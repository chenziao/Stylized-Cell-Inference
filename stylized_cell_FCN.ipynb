{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import h5py\n",
    "import json\n",
    "import os\n",
    "\n",
    "from cell_inference.config import paths, params\n",
    "from cell_inference.utils.plotting.plot_results import plot_lfp_traces, plot_lfp_heatmap\n",
    "from cell_inference.utils.feature_extractors.SummaryStats2D import calculate_stats, build_lfp_grid\n",
    "from cell_inference.utils.feature_extractors.parameterprediction import ClassifierTypes, ClassifierBuilder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y', 'd', 'theta', 'h', 'phi']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>d</th>\n",
       "      <th>theta</th>\n",
       "      <th>h</th>\n",
       "      <th>phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-132.540830</td>\n",
       "      <td>141.725841</td>\n",
       "      <td>-0.032450</td>\n",
       "      <td>0.369646</td>\n",
       "      <td>-1.861283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-111.224290</td>\n",
       "      <td>127.695576</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>-0.142611</td>\n",
       "      <td>0.045752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-102.280518</td>\n",
       "      <td>163.525782</td>\n",
       "      <td>0.443308</td>\n",
       "      <td>-0.503671</td>\n",
       "      <td>1.759341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-79.567411</td>\n",
       "      <td>140.102742</td>\n",
       "      <td>0.185093</td>\n",
       "      <td>0.740001</td>\n",
       "      <td>2.408614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-65.990438</td>\n",
       "      <td>189.524516</td>\n",
       "      <td>0.024754</td>\n",
       "      <td>-0.642074</td>\n",
       "      <td>-1.370801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.826070</td>\n",
       "      <td>79.906507</td>\n",
       "      <td>-0.386840</td>\n",
       "      <td>0.750147</td>\n",
       "      <td>-0.835700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.722668</td>\n",
       "      <td>64.684229</td>\n",
       "      <td>0.151374</td>\n",
       "      <td>-0.980576</td>\n",
       "      <td>-2.605126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.456311</td>\n",
       "      <td>99.531140</td>\n",
       "      <td>0.215845</td>\n",
       "      <td>-0.116415</td>\n",
       "      <td>-2.969536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.338696</td>\n",
       "      <td>141.096088</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>-0.373789</td>\n",
       "      <td>-1.365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.292317</td>\n",
       "      <td>77.016501</td>\n",
       "      <td>-0.045662</td>\n",
       "      <td>-0.651252</td>\n",
       "      <td>-1.632723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y           d     theta         h       phi\n",
       "3  -132.540830  141.725841 -0.032450  0.369646 -1.861283\n",
       "6  -111.224290  127.695576  0.047458 -0.142611  0.045752\n",
       "2  -102.280518  163.525782  0.443308 -0.503671  1.759341\n",
       "12  -79.567411  140.102742  0.185093  0.740001  2.408614\n",
       "9   -65.990438  189.524516  0.024754 -0.642074 -1.370801\n",
       "..         ...         ...       ...       ...       ...\n",
       "5     5.826070   79.906507 -0.386840  0.750147 -0.835700\n",
       "10   16.722668   64.684229  0.151374 -0.980576 -2.605126\n",
       "14   20.456311   99.531140  0.215845 -0.116415 -2.969536\n",
       "8    53.338696  141.096088  0.021343 -0.373789 -1.365200\n",
       "1    82.292317   77.016501 -0.045662 -0.651252 -1.632723\n",
       "\n",
       "[20 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_PATH = 'cell_inference/resources/simulation_data'\n",
    "TRIAL_PATH = os.path.join(DATA_PATH, 'neuronal_model_491766131_Loc5')\n",
    "\n",
    "CONFIG_PATH = os.path.join(TRIAL_PATH, 'config.json')  # trial configuration\n",
    "LFP_PATH = os.path.join(TRIAL_PATH, 'lfp.npz')  # LFP and labels\n",
    "STATS_PATH = os.path.join(TRIAL_PATH, 'summ_stats.npz')  # summary statistics\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "inference_list = config_dict['Trial_Parameters']['inference_list']\n",
    "print(inference_list)\n",
    "\n",
    "STATS = np.load(STATS_PATH)\n",
    "summ_stats = STATS['x']\n",
    "labels = STATS['y']\n",
    "df_la = pd.DataFrame(labels, columns=inference_list)\n",
    "yshift = 'y' in inference_list and STATS['ys'].size != 0\n",
    "if yshift:\n",
    "    labels[:,inference_list.index('y')] = STATS['ys']\n",
    "    df_la.sort_values(by='y',inplace=True)\n",
    "\n",
    "with pd.option_context('display.max_rows',10):\n",
    "    display(df_la)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set bounds for y shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"x\": [-50, 50], \"y\": [-1400, 1400], \"z\": [20.0, 200.0], \"alpha\": [0, 3.141592653589793], \"h\": [-1.0, 1.0], \"phi\": [-3.141592653589793, 3.141592653589793], \"d\": [20.0, 200.0], \"theta\": [-1.0471975511965976, 1.0471975511965976], \"r_s\": [5.0, 12.0], \"l_t\": [20.0, 800.0], \"r_t\": [0.25, 0.8], \"r_d\": [0.15, 0.45], \"r_tu\": [0.15, 0.45], \"l_d\": [100.0, 300.0], \"r_a\": [0.15, 0.45]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>d</th>\n",
       "      <th>theta</th>\n",
       "      <th>h</th>\n",
       "      <th>phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-132.540830</td>\n",
       "      <td>141.725841</td>\n",
       "      <td>-0.032450</td>\n",
       "      <td>0.369646</td>\n",
       "      <td>-1.861283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-111.224290</td>\n",
       "      <td>127.695576</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>-0.142611</td>\n",
       "      <td>0.045752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-102.280518</td>\n",
       "      <td>163.525782</td>\n",
       "      <td>0.443308</td>\n",
       "      <td>-0.503671</td>\n",
       "      <td>1.759341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-79.567411</td>\n",
       "      <td>140.102742</td>\n",
       "      <td>0.185093</td>\n",
       "      <td>0.740001</td>\n",
       "      <td>2.408614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-65.990438</td>\n",
       "      <td>189.524516</td>\n",
       "      <td>0.024754</td>\n",
       "      <td>-0.642074</td>\n",
       "      <td>-1.370801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.826070</td>\n",
       "      <td>79.906507</td>\n",
       "      <td>-0.386840</td>\n",
       "      <td>0.750147</td>\n",
       "      <td>-0.835700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.722668</td>\n",
       "      <td>64.684229</td>\n",
       "      <td>0.151374</td>\n",
       "      <td>-0.980576</td>\n",
       "      <td>-2.605126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.456311</td>\n",
       "      <td>99.531140</td>\n",
       "      <td>0.215845</td>\n",
       "      <td>-0.116415</td>\n",
       "      <td>-2.969536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>53.338696</td>\n",
       "      <td>141.096088</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>-0.373789</td>\n",
       "      <td>-1.365200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82.292317</td>\n",
       "      <td>77.016501</td>\n",
       "      <td>-0.045662</td>\n",
       "      <td>-0.651252</td>\n",
       "      <td>-1.632723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y           d     theta         h       phi\n",
       "3  -132.540830  141.725841 -0.032450  0.369646 -1.861283\n",
       "6  -111.224290  127.695576  0.047458 -0.142611  0.045752\n",
       "2  -102.280518  163.525782  0.443308 -0.503671  1.759341\n",
       "12  -79.567411  140.102742  0.185093  0.740001  2.408614\n",
       "9   -65.990438  189.524516  0.024754 -0.642074 -1.370801\n",
       "..         ...         ...       ...       ...       ...\n",
       "5     5.826070   79.906507 -0.386840  0.750147 -0.835700\n",
       "10   16.722668   64.684229  0.151374 -0.980576 -2.605126\n",
       "14   20.456311   99.531140  0.215845 -0.116415 -2.969536\n",
       "8    53.338696  141.096088  0.021343 -0.373789 -1.365200\n",
       "1    82.292317   77.016501 -0.045662 -0.651252 -1.632723\n",
       "\n",
       "[20 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ranges = config_dict['Simulation_Parameters']['loc_param_range']\n",
    "ranges.update(config_dict['Simulation_Parameters']['geo_param_range'])\n",
    "print(json.dumps(ranges))\n",
    "\n",
    "if yshift:\n",
    "    ranges['y'] = [-150, 150]\n",
    "    df_la_idx = df_la[df_la['y'].between(*ranges['y'])].index.values\n",
    "    labels = labels[df_la_idx,:]\n",
    "    summ_stats = summ_stats[df_la_idx,:]\n",
    "    with pd.option_context('display.max_rows',10):\n",
    "        display(df_la.loc[df_la_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>d</th>\n",
       "      <th>theta</th>\n",
       "      <th>h</th>\n",
       "      <th>phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.883606</td>\n",
       "      <td>0.352509</td>\n",
       "      <td>-0.030987</td>\n",
       "      <td>0.369646</td>\n",
       "      <td>-0.592465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.741495</td>\n",
       "      <td>0.196618</td>\n",
       "      <td>0.045319</td>\n",
       "      <td>-0.142611</td>\n",
       "      <td>0.014563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.681870</td>\n",
       "      <td>0.594731</td>\n",
       "      <td>0.423328</td>\n",
       "      <td>-0.503671</td>\n",
       "      <td>0.560016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.530449</td>\n",
       "      <td>0.334475</td>\n",
       "      <td>0.176751</td>\n",
       "      <td>0.740001</td>\n",
       "      <td>0.766686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.439936</td>\n",
       "      <td>0.883606</td>\n",
       "      <td>0.023638</td>\n",
       "      <td>-0.642074</td>\n",
       "      <td>-0.436339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.038840</td>\n",
       "      <td>-0.334372</td>\n",
       "      <td>-0.369405</td>\n",
       "      <td>0.750147</td>\n",
       "      <td>-0.266012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.111484</td>\n",
       "      <td>-0.503509</td>\n",
       "      <td>0.144552</td>\n",
       "      <td>-0.980576</td>\n",
       "      <td>-0.829237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.136375</td>\n",
       "      <td>-0.116321</td>\n",
       "      <td>0.206117</td>\n",
       "      <td>-0.116415</td>\n",
       "      <td>-0.945233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.355591</td>\n",
       "      <td>0.345512</td>\n",
       "      <td>0.020381</td>\n",
       "      <td>-0.373789</td>\n",
       "      <td>-0.434557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.548615</td>\n",
       "      <td>-0.366483</td>\n",
       "      <td>-0.043604</td>\n",
       "      <td>-0.651252</td>\n",
       "      <td>-0.519712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           y         d     theta         h       phi\n",
       "0  -0.883606  0.352509 -0.030987  0.369646 -0.592465\n",
       "1  -0.741495  0.196618  0.045319 -0.142611  0.014563\n",
       "2  -0.681870  0.594731  0.423328 -0.503671  0.560016\n",
       "3  -0.530449  0.334475  0.176751  0.740001  0.766686\n",
       "4  -0.439936  0.883606  0.023638 -0.642074 -0.436339\n",
       "..       ...       ...       ...       ...       ...\n",
       "15  0.038840 -0.334372 -0.369405  0.750147 -0.266012\n",
       "16  0.111484 -0.503509  0.144552 -0.980576 -0.829237\n",
       "17  0.136375 -0.116321  0.206117 -0.116415 -0.945233\n",
       "18  0.355591  0.345512  0.020381 -0.373789 -0.434557\n",
       "19  0.548615 -0.366483 -0.043604 -0.651252 -0.519712\n",
       "\n",
       "[20 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "for i, lb in enumerate(inference_list):\n",
    "    x_std = (labels[:,i] - ranges[lb][0]) / (ranges[lb][1] - ranges[lb][0])\n",
    "    labels[:,i] = x_std * (feature_range[1] - feature_range[0]) + feature_range[0]\n",
    "df_la = pd.DataFrame(labels, columns=inference_list)\n",
    "with pd.option_context('display.max_rows',10):\n",
    "    display(df_la)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from cell_inference.utils.feature_extractors.fullyconnectednetwork import FullyConnectedNetwork, ActivationTypes\n",
    "# from cell_inference.utils.feature_extractors.convolutionalnetwork import ConvolutionalNetwork\n",
    "\n",
    "model = FullyConnectedNetwork(in_features=summ_stats.shape[1], out_features=labels.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'FCN_batch128.pth'\n",
    "MODEL_PATH = os.path.join(TRIAL_PATH,model_name)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from cell_inference.utils.transform.geometry_transformation import hphi2unitsphere, unitsphere2hphi, trivarnorm2unitsphere\n",
    "from cell_inference.utils.feature_extractors.helperfunctions import build_dataloader_from_numpy\n",
    "from cell_inference.utils.metrics.corrcoef import corrcoef\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "train_loader, test_loader = build_dataloader_from_numpy(input_arr=summ_stats, labels_arr=labels, batch_size=512, shuffle=True)\n",
    "\n",
    "x, y = next(iter(test_loader))\n",
    "model.eval()\n",
    "x = x.to(device)\n",
    "output = model(x)\n",
    "output = output.to(\"cpu\").detach().numpy()\n",
    "y = y.to(\"cpu\").detach().numpy()\n",
    "\n",
    "# print(\"R2: {}\".format(r2_score(y, output)))\n",
    "print('R2 Score Y-Shift: {}'.format(r2_score(y[:,0], output[:,0])))\n",
    "print('R2 Score D: {}'.format(r2_score(y[:,1], output[:,1])))\n",
    "print('R2 Score Theta: {}'.format(r2_score(y[:,2], output[:,2])))\n",
    "print('R2 Score h: {}'.format(r2_score(y[:,3], output[:,3])))\n",
    "print('R2 Score Phi: {}'.format(r2_score(y[:,4], output[:,4])))\n",
    "print('R2 Score Soma Radius: {}'.format(r2_score(y[:,5], output[:,5])))\n",
    "print('R2 Score Trunk Length: {}'.format(r2_score(y[:,6], output[:,6])))\n",
    "print('R2 Score Trunk Width: {}'.format(r2_score(y[:,7], output[:,7])))\n",
    "\n",
    "\n",
    "# print(output.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "df_la = pd.DataFrame(y, columns=inference_list).sort_values(by='y')\n",
    "display(df_la)\n",
    "# print(y[:,0])\n",
    "# print(output[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for i in range(y.shape[1]):\n",
    "        old_y = y[:,i]\n",
    "        old_out = output[:,i]\n",
    "        label_name = inference_list[i]\n",
    "        min_max_range = ranges[label_name]\n",
    "        org_y = (((old_y - feature_range[0]) / (feature_range[1] - feature_range[0])) \n",
    "                    * (min_max_range[1] - min_max_range[0]) + min_max_range[0])\n",
    "        \n",
    "        org_out = (((old_out - feature_range[0]) / (feature_range[1] - feature_range[0])) \n",
    "                    * (min_max_range[1] - min_max_range[0]) + min_max_range[0])\n",
    "        y[:,i] = org_y\n",
    "        output[:,i] = org_out\n",
    "\n",
    "# print(y[:,0])\n",
    "# print(output[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "idx = 0\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.suptitle(\"Stylized Cell Actual VS Predicted Parameters\", fontsize=30)\n",
    "fontsize = 25\n",
    "labelsize = 25\n",
    "\n",
    "lab_ax = 0\n",
    "ax = plt.subplot(331)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('y-shift actual', fontsize=fontsize)\n",
    "ax.set_ylabel('y-shift predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 1\n",
    "ax = plt.subplot(332)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('d actual', fontsize=fontsize)\n",
    "ax.set_ylabel('d predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 2\n",
    "ax = plt.subplot(333)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel(r'$\\theta$ actual', fontsize=fontsize)\n",
    "ax.set_ylabel(r'$\\theta$ predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 3\n",
    "ax = plt.subplot(334)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('h actual', fontsize=fontsize)\n",
    "ax.set_ylabel('h predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 4\n",
    "ax = plt.subplot(335)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel(r'$\\varphi$ actual', fontsize=fontsize)\n",
    "ax.set_ylabel(r'$\\varphi$ predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 5\n",
    "ax = plt.subplot(336)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('soma radius actual', fontsize=fontsize)\n",
    "ax.set_ylabel('soma radius predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 6\n",
    "ax = plt.subplot(337)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('trunk length actual', fontsize=fontsize)\n",
    "ax.set_ylabel('trunk length predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 7\n",
    "ax = plt.subplot(338)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('trunk radius actual', fontsize=fontsize)\n",
    "ax.set_ylabel('trunk radius predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "plt.tight_layout(pad=3., rect=[0, 0.03, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_inference.utils.feature_extractors.SummaryStats2D import get_y_window\n",
    "from tqdm.notebook import tqdm\n",
    "from cell_inference.utils.spike_window import first_pk_tr, get_spike_window\n",
    "\n",
    "DATA_PATH = 'cell_inference/resources/invivo'\n",
    "\n",
    "INVIVO_PATH = os.path.join(DATA_PATH, 'all_cell_LFP_2D.h5')\n",
    "\n",
    "with h5py.File(INVIVO_PATH, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    c = f['coord'][:]\n",
    "    d = f['data'][:]  # time x channels x samples\n",
    "    ids = f['ID'][:]\n",
    "\n",
    "t = np.arange(d.shape[0])\n",
    "\n",
    "scaler = 7720.0\n",
    "\n",
    "filtered_lfp = np.divide(d, scaler)\n",
    "\n",
    "pk_tr_idx_in_window = 16  # 16*0.025=0.4 ms\n",
    "lfp_list = []\n",
    "for i in range(d.shape[2]):\n",
    "    #     filtered_lfp[i] /= np.max(np.abs(filtered_lfp[i]))\n",
    "    fst_idx = first_pk_tr(filtered_lfp[:,:,i])\n",
    "    start, end = get_spike_window(filtered_lfp[:,:,i], win_size=params.WINDOW_SIZE, align_at=pk_tr_idx_in_window)\n",
    "    lfp_list.append(filtered_lfp[start:end, :, i])\n",
    "\n",
    "windowed_lfp = np.stack(lfp_list, axis=0)  # (samples x time window x channels)\n",
    "\n",
    "test_data = []\n",
    "summ_stats = []\n",
    "bad_indices = []\n",
    "y_pos = []\n",
    "for i in tqdm(range(windowed_lfp.shape[0])):\n",
    "    try:\n",
    "        g_lfp, g_coords, y_i = build_lfp_grid(windowed_lfp[i, :, :], params.ELECTRODE_POSITION[:, :2], y_window_size=960.0)\n",
    "    except ValueError:\n",
    "        # windowed_lfp = np.delete(windowed_lfp, i, axis=0)\n",
    "        # self.labels = np.delete(self.labels, i, axis=0)\n",
    "        bad_indices.append(i)\n",
    "        continue\n",
    "    test_data.append(g_lfp)\n",
    "    summ_stats.append(calculate_stats(g_lfp))\n",
    "    y_pos.append(y_i)\n",
    "    \n",
    "ids = np.delete(ids, bad_indices, axis=0)\n",
    "test_data = np.stack(test_data, axis=0)\n",
    "summ_stats = np.array(summ_stats)\n",
    "y_pos = np.stack(y_pos, axis=0)\n",
    "print(test_data.shape, summ_stats.shape, y_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = y_pos.reshape((-1,))\n",
    "# print(y_pos)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "model.eval()\n",
    "summ_stats = torch.Tensor(summ_stats)\n",
    "summ_stats_tensor = summ_stats.to(device)\n",
    "pred = model(summ_stats_tensor)\n",
    "pred = pred.to(\"cpu\").detach().numpy()\n",
    "\n",
    "# print(pred[:, 0].shape)\n",
    "\n",
    "if True:\n",
    "    for i in range(pred.shape[1]):\n",
    "        old_pred = pred[:,i]\n",
    "        label_name = inference_list[i]\n",
    "        min_max_range = ranges[label_name]\n",
    "        org_pred = (((old_pred - feature_range[0]) / (feature_range[1] - feature_range[0])) \n",
    "                    * (min_max_range[1] - min_max_range[0]) + min_max_range[0])\n",
    "        pred[:,i] = org_pred\n",
    "\n",
    "pred[:,0] = y_pos - pred[:, 0]\n",
    "\n",
    "\n",
    "# idx_map = np.stack((np.arange(ids.shape[0]), ids), axis=-1)\n",
    "# idx_map = dict(enumerate(ids.flatten()))\n",
    "# print(ids.flatten())\n",
    "# print(idx_map)\n",
    "        \n",
    "y_pred = pred\n",
    "df = pd.DataFrame(y_pred, columns=inference_list)#.sort_values(by='y')\n",
    "# df = df.rename(index=idx_map)\n",
    "df['cell_id'] = ids.flatten()\n",
    "# df = df[df['y'].between(-700,700)]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['r_s'] = df['r_s'].clip(ranges['r_s'][0], ranges['r_s'][1])\n",
    "df['l_t'] = df['l_t'].clip(ranges['l_t'][0], ranges['l_t'][1])\n",
    "df['r_t'] = df['r_t'].clip(ranges['r_t'][0], ranges['r_t'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(test_data.shape[1])\n",
    "\n",
    "ix = 1\n",
    "ylim = [-1900,1900]\n",
    "x_dist = np.unique(g_coords[:,0])\n",
    "e_idx = ((g_coords[:,0]==x_dist[ix]) & \n",
    "         (g_coords[:,1]>=ylim[0]) & \n",
    "         (g_coords[:,1]<=ylim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_inference.utils.metrics.prediction_verification import InVivoParamSimulator\n",
    "\n",
    "simu = InVivoParamSimulator(df)\n",
    "lfp, t = simu.verify_and_save(save=False)\n",
    "\n",
    "print(lfp.shape)\n",
    "data_set = []\n",
    "bad_indices = []\n",
    "coordinates = []\n",
    "for i in tqdm(range(lfp.shape[0])):\n",
    "    try:\n",
    "        g_lfp, g_coords, y_i = build_lfp_grid(lfp[i, :, :], params.ELECTRODE_POSITION[:, :2], y_window_size=960.0)\n",
    "    except ValueError:\n",
    "        bad_indices.append(i)\n",
    "        continue\n",
    "    data_set.append(g_lfp)\n",
    "    coordinates.append(g_coords)\n",
    "data_set = np.stack(data_set, axis=0)\n",
    "coordinates = np.stack(coordinates, axis=0)\n",
    "\n",
    "test_data = np.delete(test_data, bad_indices, axis=0)\n",
    "ids = np.delete(ids, bad_indices, axis=0)\n",
    "df = df.drop(index=bad_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "import cell_inference.utils.plotting.plot_results\n",
    "reload(cell_inference.utils.plotting.plot_results)\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "from cell_inference.utils.plotting.plot_results import plot_multiple_lfp_heatmaps\n",
    "\n",
    "\n",
    "for j, (i, row) in enumerate(df.iterrows()):\n",
    "#     if i < 20:\n",
    "#         continue\n",
    "    fig=plt.figure(figsize=(15,4))\n",
    "    outer=GridSpec(1,2)\n",
    "    \n",
    "#     In Vivo Plot\n",
    "    vlim = plot_multiple_lfp_heatmaps(t,\n",
    "                                   coordinates[j, e_idx, 1],\n",
    "                                   np.transpose(test_data[j,:,e_idx]), \n",
    "#                                    savefig='lfp_heatmaps/realinvivo' + str(i) + '.jpg',\n",
    "                                   vlim='auto',\n",
    "                                   fontsize=18,labelpad=0,ticksize=15,nbins=5,\n",
    "                                   fig=fig, outer=outer, col=0, cell_num=0, title='In Vivo Cell {}'.format(row['cell_id']))\n",
    "\n",
    "    # Predicted In Vivo From Params\n",
    "    plot_multiple_lfp_heatmaps(t,\n",
    "                                   coordinates[j, e_idx, 1],\n",
    "                                   np.transpose(data_set[j,:,e_idx]), \n",
    "#                                    savefig='lfp_heatmaps/predictedinvivo' + str(i) + '.jpg',\n",
    "                                   vlim=vlim,\n",
    "                                   fontsize=18,labelpad=0,ticksize=15,nbins=5,\n",
    "                                   fig=fig, outer=outer, col=1, cell_num=0, title='Predicted Cell {}'.format(row['cell_id']))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('lfp_heatmaps/' + str(row['cell_id']) + '.jpg')\n",
    "#     if i == 22:\n",
    "#         break\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('invivo_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_inference.utils.metrics.corrcoef import corrcoef\n",
    "\n",
    "corrcoef_list = np.array([corrcoef(test_data[i,:,:], data_set[i,:,:]) for i in range(data_set.shape[0])])\n",
    "\n",
    "maidx = np.argmax(corrcoef_list)\n",
    "miidx = np.argmin(corrcoef_list)\n",
    "print('Max Index: {}'.format(maidx))\n",
    "print('Min Index: {}'.format(miidx))\n",
    "\n",
    "plt.hist(corrcoef_list, bins=20)\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Count')\n",
    "plt.title('In Vivo vs Predicted Correlation Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.figure(figsize=(15,10))\n",
    "\n",
    "for i in [miidx, maidx]:\n",
    "    fig=plt.figure(figsize=(15,4))\n",
    "    outer=GridSpec(1,2)\n",
    "#     print(df.loc[i, 'cell_id'])\n",
    "#     In Vivo Plot\n",
    "    vlim = plot_multiple_lfp_heatmaps(t,\n",
    "                                   coordinates[i, e_idx, 1],\n",
    "                                   np.transpose(test_data[i,:,e_idx]), \n",
    "#                                    savefig='lfp_heatmaps/realinvivo' + str(i) + '.jpg',\n",
    "                                   vlim='auto',\n",
    "                                   fontsize=18,labelpad=0,ticksize=15,nbins=5,\n",
    "                                   fig=fig, outer=outer, col=0, cell_num=0, title='In Vivo Cell {}'.format(df.loc[i, 'cell_id']))\n",
    "\n",
    "    # Predicted In Vivo From Params\n",
    "    plot_multiple_lfp_heatmaps(t,\n",
    "                                   coordinates[i, e_idx, 1],\n",
    "                                   np.transpose(data_set[i,:,e_idx]), \n",
    "#                                    savefig='lfp_heatmaps/predictedinvivo' + str(i) + '.jpg',\n",
    "                                   vlim=vlim,\n",
    "                                   fontsize=18,labelpad=0,ticksize=15,nbins=5,\n",
    "                                   fig=fig, outer=outer, col=1, cell_num=0, title='Predicted Cell {}'.format(df.loc[i, 'cell_id']))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from importlib import reload\n",
    "# import cell_inference.utils.plotting.plot_all_cells\n",
    "# reload(cell_inference.utils.plotting.plot_all_cells)\n",
    "from cell_inference.utils.plotting.plot_all_cells import plot_all_cells\n",
    "\n",
    "fig, ax = plot_all_cells(df, figsize=(15., 15.))\n",
    "ax.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "LOSS_PATH = 'cell_inference/resources/results/pytorch_losses/13_43_39__02_14_2022.csv'\n",
    "loss_df = pd.read_csv(LOSS_PATH)\n",
    "\n",
    "t_loss = loss_df['Training_Loss'].to_numpy() # / 86729\n",
    "epochs = np.arange(t_loss.shape[0])\n",
    "\n",
    "v_loss = loss_df['Validation_Loss'].to_numpy() # / 28910\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "\n",
    "fig.suptitle(\"Loss Graphs\", fontsize=40)\n",
    "gs=GridSpec(2,2)\n",
    "\n",
    "ax1=fig.add_subplot(gs[0,:]) \n",
    "ax2=fig.add_subplot(gs[1,0]) \n",
    "ax3=fig.add_subplot(gs[1,1]) \n",
    "\n",
    "ax1.plot(epochs, t_loss, label='Training Loss')\n",
    "ax1.plot(epochs, v_loss, label='Validation Loss')\n",
    "ax1.tick_params(labelsize=20)\n",
    "ax1.set_ylim(bottom=15, top=120)\n",
    "# ax1.set_xlabel('Epoch', fontsize=40)\n",
    "ax1.set_ylabel('Loss', fontsize=30)\n",
    "ax1.legend(fontsize=15)\n",
    "\n",
    "ax2.plot(epochs, t_loss, label='Training Loss')\n",
    "ax2.tick_params(labelsize=20)\n",
    "ax2.set_ylim(bottom=40, top=120)\n",
    "ax2.set_xlabel('Epoch', fontsize=30)\n",
    "ax2.set_ylabel('Loss', fontsize=30)\n",
    "ax2.set_title('Training', fontsize=20)\n",
    "\n",
    "ax3.plot(epochs, v_loss, label='Validation Loss')\n",
    "ax3.tick_params(labelsize=20)\n",
    "ax3.set_xlabel('Epoch', fontsize=30)\n",
    "ax3.set_title('Validation', fontsize=20)\n",
    "# ax3.set_ylabel('Loss', fontsize=40)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# print(t_loss)\n",
    "# display(loss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
