{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from neuron import h\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import h5py\n",
    "import os\n",
    "\n",
    "from cell_inference.cells.stylizedcell import CellTypes\n",
    "from cell_inference.config import paths, params\n",
    "\n",
    "\n",
    "cell_type = CellTypes.ACTIVE\n",
    "\n",
    "h.nrn_load_dll(paths.COMPILED_LIBRARY)\n",
    "geo_standard = pd.read_csv(paths.GEO_STANDARD,index_col='id')\n",
    "h.tstop = params.TSTOP\n",
    "h.dt = params.DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_inference.utils.plotting.plot_results import plot_lfp_traces, plot_lfp_heatmap\n",
    "from cell_inference.utils.feature_extractors.SummaryStats2D import calculate_stats, build_lfp_grid\n",
    "from cell_inference.cells.activecell import ActiveCell\n",
    "from cell_inference.cells.passivecell import PassiveCell\n",
    "from cell_inference.cells.simulation import Simulation\n",
    "from cell_inference.utils.currents.recorder import Recorder\n",
    "from cell_inference.utils.feature_extractors.parameterprediction import ClassifierTypes, ClassifierBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y', 'd', 'theta', 'h', 'phi', 'r_s', 'l_t', 'r_t']\n",
      "{'x': [-50, 50], 'y': [-100, 100], 'z': [20.0, 200.0], 'alpha': [0, 3.141592653589793], 'h': [-1.0, 1.0], 'phi': [-3.141592653589793, 3.141592653589793], 'd': [20.0, 200.0], 'theta': [-1.0471975511965976, 1.0471975511965976], 'r_s': [7.0, 12.0], 'l_t': [20.0, 800.0], 'r_t': [0.6, 1.8], 'r_d': [0.1, 0.8], 'r_tu': [0.1, 0.8], 'l_d': [100.0, 300.0]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>d</th>\n",
       "      <th>theta</th>\n",
       "      <th>h</th>\n",
       "      <th>phi</th>\n",
       "      <th>r_s</th>\n",
       "      <th>l_t</th>\n",
       "      <th>r_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>-99.122356</td>\n",
       "      <td>158.567656</td>\n",
       "      <td>-0.282863</td>\n",
       "      <td>-0.602610</td>\n",
       "      <td>-2.723164</td>\n",
       "      <td>9.146831</td>\n",
       "      <td>298.260572</td>\n",
       "      <td>1.082463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-96.539589</td>\n",
       "      <td>55.502291</td>\n",
       "      <td>-0.605595</td>\n",
       "      <td>-0.803406</td>\n",
       "      <td>2.010273</td>\n",
       "      <td>8.936617</td>\n",
       "      <td>317.455527</td>\n",
       "      <td>1.548819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>-96.525035</td>\n",
       "      <td>177.234074</td>\n",
       "      <td>-0.398543</td>\n",
       "      <td>0.908610</td>\n",
       "      <td>0.578021</td>\n",
       "      <td>10.245818</td>\n",
       "      <td>52.762555</td>\n",
       "      <td>0.877110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>-94.839032</td>\n",
       "      <td>52.888206</td>\n",
       "      <td>0.047551</td>\n",
       "      <td>-0.877754</td>\n",
       "      <td>-2.328690</td>\n",
       "      <td>10.672544</td>\n",
       "      <td>101.318815</td>\n",
       "      <td>1.456209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-93.292155</td>\n",
       "      <td>190.809861</td>\n",
       "      <td>-0.013818</td>\n",
       "      <td>-0.501318</td>\n",
       "      <td>-1.984062</td>\n",
       "      <td>11.886048</td>\n",
       "      <td>486.295251</td>\n",
       "      <td>1.207861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>95.969824</td>\n",
       "      <td>181.585718</td>\n",
       "      <td>-0.649512</td>\n",
       "      <td>0.844816</td>\n",
       "      <td>2.558533</td>\n",
       "      <td>7.377579</td>\n",
       "      <td>87.041720</td>\n",
       "      <td>1.068007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>97.727256</td>\n",
       "      <td>153.988531</td>\n",
       "      <td>0.297392</td>\n",
       "      <td>0.571833</td>\n",
       "      <td>-3.131668</td>\n",
       "      <td>11.248819</td>\n",
       "      <td>737.365449</td>\n",
       "      <td>1.403897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>97.880291</td>\n",
       "      <td>136.032043</td>\n",
       "      <td>0.393296</td>\n",
       "      <td>0.626986</td>\n",
       "      <td>3.000355</td>\n",
       "      <td>8.189393</td>\n",
       "      <td>628.632922</td>\n",
       "      <td>1.299157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>98.605421</td>\n",
       "      <td>103.316206</td>\n",
       "      <td>-0.322245</td>\n",
       "      <td>0.700942</td>\n",
       "      <td>2.492166</td>\n",
       "      <td>8.062453</td>\n",
       "      <td>178.569475</td>\n",
       "      <td>0.602166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>99.425542</td>\n",
       "      <td>123.843376</td>\n",
       "      <td>0.621167</td>\n",
       "      <td>0.913625</td>\n",
       "      <td>-1.691138</td>\n",
       "      <td>7.191038</td>\n",
       "      <td>60.905133</td>\n",
       "      <td>1.597152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>873 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             y           d     theta         h       phi        r_s  \\\n",
       "889 -99.122356  158.567656 -0.282863 -0.602610 -2.723164   9.146831   \n",
       "235 -96.539589   55.502291 -0.605595 -0.803406  2.010273   8.936617   \n",
       "215 -96.525035  177.234074 -0.398543  0.908610  0.578021  10.245818   \n",
       "502 -94.839032   52.888206  0.047551 -0.877754 -2.328690  10.672544   \n",
       "77  -93.292155  190.809861 -0.013818 -0.501318 -1.984062  11.886048   \n",
       "..         ...         ...       ...       ...       ...        ...   \n",
       "504  95.969824  181.585718 -0.649512  0.844816  2.558533   7.377579   \n",
       "269  97.727256  153.988531  0.297392  0.571833 -3.131668  11.248819   \n",
       "901  97.880291  136.032043  0.393296  0.626986  3.000355   8.189393   \n",
       "433  98.605421  103.316206 -0.322245  0.700942  2.492166   8.062453   \n",
       "478  99.425542  123.843376  0.621167  0.913625 -1.691138   7.191038   \n",
       "\n",
       "            l_t       r_t  \n",
       "889  298.260572  1.082463  \n",
       "235  317.455527  1.548819  \n",
       "215   52.762555  0.877110  \n",
       "502  101.318815  1.456209  \n",
       "77   486.295251  1.207861  \n",
       "..          ...       ...  \n",
       "504   87.041720  1.068007  \n",
       "269  737.365449  1.403897  \n",
       "901  628.632922  1.299157  \n",
       "433  178.569475  0.602166  \n",
       "478   60.905133  1.597152  \n",
       "\n",
       "[873 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "CONFIG_PATH = os.path.join('cell_inference/resources/simulation_data/1000s_y1Loc2Alt_Ori2_Geo3_params/config0.json')\n",
    "\n",
    "with open(CONFIG_PATH, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "inference_list = config['Trial_Parameters']['inference_list']\n",
    "ranges = config['Simulation_Parameters']['loc_param_range']\n",
    "ranges.update(config['Simulation_Parameters']['geo_param_range'])\n",
    "ranges['y'] = [-100, 100]\n",
    "feature_range = (-1, 1)\n",
    "\n",
    "print(inference_list)\n",
    "print(ranges)\n",
    "\n",
    "DATA_PATH = 'cell_inference/resources/simulation_data'\n",
    "TRIAL_PATH = os.path.join(DATA_PATH, '1000s_y1Loc2Alt_Ori2_Geo3_params')\n",
    "\n",
    "LFP_PATH = os.path.join(TRIAL_PATH, 'summ_stats0.npz')  # LFP and labels\n",
    "\n",
    "summ_stats   = np.load(LFP_PATH)['x']\n",
    "labels = np.load(LFP_PATH)['y']\n",
    "\n",
    "labels[:,0] = np.load(LFP_PATH)['ys']\n",
    "\n",
    "df_la = pd.DataFrame(labels, columns=inference_list).sort_values(by='y')\n",
    "# display(df_la)\n",
    "df_bet_la = df_la[df_la['y'].between(-100, 100)].index.values\n",
    "\n",
    "labels = labels[df_bet_la,:]\n",
    "summ_stats = summ_stats[df_bet_la,:]\n",
    "display(df_la[df_la['y'].between(-100, 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(989, 176, 384)\n",
      "<KeysViewHDF5 ['data']>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2cf5afda939a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_invp_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_styl_max\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0minvp_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyl_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvp_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyl_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2cf5afda939a>\u001b[0m in \u001b[0;36mtest_max\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpk_tr_idx_in_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m  \u001b[0;31m# 16*0.025=0.4 ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mlfp_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m#     filtered_lfp[i] /= np.max(np.abs(filtered_lfp[i]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mfst_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_pk_tr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_lfp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from cell_inference.utils.spike_window import first_pk_tr, get_spike_window\n",
    "\n",
    "def test_max():\n",
    "    lp = os.path.join(TRIAL_PATH, 'lfp0.npz')  # LFP and labels\n",
    "    lfp = np.load(lp)['x']\n",
    "    print(lfp.shape)\n",
    "\n",
    "    dp = 'cell_inference/resources/invivo'\n",
    "    invp = os.path.join(dp, 'all_cell_LFP_2D.h5')\n",
    "\n",
    "    with h5py.File(invp, \"r\") as f:\n",
    "        c = f['coord'][:]\n",
    "        d = f['data'][:]  # time x channels x samples\n",
    "\n",
    "    t = np.arange(d.shape[0])\n",
    "\n",
    "    filtered_lfp = d\n",
    "\n",
    "    pk_tr_idx_in_window = 16  # 16*0.025=0.4 ms\n",
    "    lfp_list = []\n",
    "    for i in range(d.shape[2]):\n",
    "        #     filtered_lfp[i] /= np.max(np.abs(filtered_lfp[i]))\n",
    "        fst_idx = first_pk_tr(filtered_lfp[:,:,i])\n",
    "        start, end = get_spike_window(filtered_lfp[:,:,i], win_size=params.WINDOW_SIZE, align_at=pk_tr_idx_in_window)\n",
    "        lfp_list.append(filtered_lfp[start:end, :, i])\n",
    "\n",
    "    windowed_lfp = np.stack(lfp_list, axis=0)  # (samples x time window x channels)\n",
    "    maxs = []\n",
    "    for i in range(windowed_lfp.shape[0]):\n",
    "        maxs.append(np.amax(windowed_lfp[i,:,:]))\n",
    "    avg_invp_max = sum(maxs)/len(maxs)\n",
    "    \n",
    "    maxs = []\n",
    "    for i in range(lfp.shape[0]):\n",
    "        maxs.append(np.amax(lfp[i,:,:]))\n",
    "    avg_styl_max = sum(maxs)/len(maxs)\n",
    "    \n",
    "    return avg_invp_max, avg_styl_max\n",
    "\n",
    "invp_max, styl_max = test_max()\n",
    "print(invp_max, styl_max)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(labels.shape[1]):\n",
    "    label = labels[:, i]\n",
    "    label_name = inference_list[i]\n",
    "    min_max_range = ranges[label_name]\n",
    "    x_std = (label - min_max_range[0]) / (min_max_range[1] - min_max_range[0])\n",
    "    x_scaled = x_std * (feature_range[1] - feature_range[0]) + feature_range[0]\n",
    "    labels[:, i] = x_scaled\n",
    "df_la = pd.DataFrame(labels, columns=inference_list).sort_values(by='y')\n",
    "display(df_la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_inference.utils.feature_extractors.fullyconnectednetwork import FullyConnectedNetwork, ActivationTypes\n",
    "from cell_inference.utils.feature_extractors.convolutionalnetwork import ConvolutionalNetwork\n",
    "import torch\n",
    "\n",
    "\n",
    "model = FullyConnectedNetwork(in_features=40, out_features=8)\n",
    "PATH = 'cell_inference/resources/simulation_data/1000s_y1Loc2Alt_Ori2_Geo3_params/batch128_model.pth'\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from cell_inference.utils.transform.geometry_transformation import hphi2unitsphere, unitsphere2hphi, trivarnorm2unitsphere\n",
    "from cell_inference.utils.feature_extractors.helperfunctions import build_dataloader_from_numpy\n",
    "from cell_inference.utils.metrics.corrcoef import corrcoef\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "train_loader, test_loader = build_dataloader_from_numpy(input_arr=summ_stats, labels_arr=labels, batch_size=512, shuffle=True)\n",
    "\n",
    "x, y = next(iter(test_loader))\n",
    "model.eval()\n",
    "x = x.to(device)\n",
    "output = model(x)\n",
    "output = output.to(\"cpu\").detach().numpy()\n",
    "y = y.to(\"cpu\").detach().numpy()\n",
    "\n",
    "# print(\"R2: {}\".format(r2_score(y, output)))\n",
    "print('R2 Score Y-Shift: {}'.format(r2_score(y[:,0], output[:,0])))\n",
    "print('R2 Score D: {}'.format(r2_score(y[:,1], output[:,1])))\n",
    "print('R2 Score Theta: {}'.format(r2_score(y[:,2], output[:,2])))\n",
    "print('R2 Score h: {}'.format(r2_score(y[:,3], output[:,3])))\n",
    "print('R2 Score Phi: {}'.format(r2_score(y[:,4], output[:,4])))\n",
    "print('R2 Score Soma Radius: {}'.format(r2_score(y[:,5], output[:,5])))\n",
    "print('R2 Score Trunk Length: {}'.format(r2_score(y[:,6], output[:,6])))\n",
    "print('R2 Score Trunk Width: {}'.format(r2_score(y[:,7], output[:,7])))\n",
    "\n",
    "\n",
    "# print(output.shape)\n",
    "# print(y.shape)\n",
    "\n",
    "df_la = pd.DataFrame(y, columns=inference_list).sort_values(by='y')\n",
    "display(df_la)\n",
    "# print(y[:,0])\n",
    "# print(output[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for i in range(y.shape[1]):\n",
    "        old_y = y[:,i]\n",
    "        old_out = output[:,i]\n",
    "        label_name = inference_list[i]\n",
    "        min_max_range = ranges[label_name]\n",
    "        org_y = (((old_y - feature_range[0]) / (feature_range[1] - feature_range[0])) \n",
    "                    * (min_max_range[1] - min_max_range[0]) + min_max_range[0])\n",
    "        \n",
    "        org_out = (((old_out - feature_range[0]) / (feature_range[1] - feature_range[0])) \n",
    "                    * (min_max_range[1] - min_max_range[0]) + min_max_range[0])\n",
    "        y[:,i] = org_y\n",
    "        output[:,i] = org_out\n",
    "\n",
    "# print(y[:,0])\n",
    "# print(output[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "idx = 0\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.suptitle(\"Stylized Cell Actual VS Predicted Parameters\", fontsize=30)\n",
    "fontsize = 25\n",
    "labelsize = 25\n",
    "\n",
    "lab_ax = 0\n",
    "ax = plt.subplot(331)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('y-shift actual', fontsize=fontsize)\n",
    "ax.set_ylabel('y-shift predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 1\n",
    "ax = plt.subplot(332)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('d actual', fontsize=fontsize)\n",
    "ax.set_ylabel('d predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 2\n",
    "ax = plt.subplot(333)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel(r'$\\theta$ actual', fontsize=fontsize)\n",
    "ax.set_ylabel(r'$\\theta$ predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 3\n",
    "ax = plt.subplot(334)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('h actual', fontsize=fontsize)\n",
    "ax.set_ylabel('h predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 4\n",
    "ax = plt.subplot(335)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel(r'$\\varphi$ actual', fontsize=fontsize)\n",
    "ax.set_ylabel(r'$\\varphi$ predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 5\n",
    "ax = plt.subplot(336)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('soma radius actual', fontsize=fontsize)\n",
    "ax.set_ylabel('soma radius predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 6\n",
    "ax = plt.subplot(337)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('trunk length actual', fontsize=fontsize)\n",
    "ax.set_ylabel('trunk length predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "lab_ax = 7\n",
    "ax = plt.subplot(338)\n",
    "ax.scatter(y[:,lab_ax], output[:,lab_ax], c='red', marker='.')\n",
    "m, b = np.polyfit(y[:,lab_ax], output[:,lab_ax], 1)\n",
    "ax.plot(y[:,lab_ax], m*y[:,lab_ax]+b, label='y = '+ str(round(m,2)) + 'x +' + str(round(b,2)))\n",
    "ax.set_xlabel('trunk radius actual', fontsize=fontsize)\n",
    "ax.set_ylabel('trunk radius predicted', fontsize=fontsize)\n",
    "ax.tick_params(labelsize=labelsize)\n",
    "ax.legend(fontsize=labelsize)\n",
    "\n",
    "plt.tight_layout(pad=3., rect=[0, 0.03, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_inference.utils.feature_extractors.SummaryStats2D import get_y_window\n",
    "from tqdm.notebook import tqdm\n",
    "from cell_inference.utils.spike_window import first_pk_tr, get_spike_window\n",
    "\n",
    "DATA_PATH = 'cell_inference/resources/invivo'\n",
    "\n",
    "INVIVO_PATH = os.path.join(DATA_PATH, 'all_cell_LFP_2D.h5')\n",
    "\n",
    "with h5py.File(INVIVO_PATH, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    c = f['coord'][:]\n",
    "    d = f['data'][:]  # time x channels x samples\n",
    "    ids = f['ID'][:]\n",
    "\n",
    "t = np.arange(d.shape[0])\n",
    "\n",
    "scaler = 7720.0\n",
    "\n",
    "filtered_lfp = np.divide(d, scaler)\n",
    "\n",
    "pk_tr_idx_in_window = 16  # 16*0.025=0.4 ms\n",
    "lfp_list = []\n",
    "for i in range(d.shape[2]):\n",
    "    #     filtered_lfp[i] /= np.max(np.abs(filtered_lfp[i]))\n",
    "    fst_idx = first_pk_tr(filtered_lfp[:,:,i])\n",
    "    start, end = get_spike_window(filtered_lfp[:,:,i], win_size=params.WINDOW_SIZE, align_at=pk_tr_idx_in_window)\n",
    "    lfp_list.append(filtered_lfp[start:end, :, i])\n",
    "\n",
    "windowed_lfp = np.stack(lfp_list, axis=0)  # (samples x time window x channels)\n",
    "\n",
    "test_data = []\n",
    "summ_stats = []\n",
    "bad_indices = []\n",
    "y_pos = []\n",
    "for i in tqdm(range(windowed_lfp.shape[0])):\n",
    "    try:\n",
    "        g_lfp, g_coords, y_i = build_lfp_grid(windowed_lfp[i, :, :], params.ELECTRODE_POSITION[:, :2], y_window_size=960.0)\n",
    "    except ValueError:\n",
    "        # windowed_lfp = np.delete(windowed_lfp, i, axis=0)\n",
    "        # self.labels = np.delete(self.labels, i, axis=0)\n",
    "        bad_indices.append(i)\n",
    "        continue\n",
    "    test_data.append(g_lfp)\n",
    "    summ_stats.append(calculate_stats(g_lfp))\n",
    "    y_pos.append(y_i)\n",
    "    \n",
    "ids = np.delete(ids, bad_indices, axis=0)\n",
    "test_data = np.stack(test_data, axis=0)\n",
    "summ_stats = np.array(summ_stats)\n",
    "y_pos = np.stack(y_pos, axis=0)\n",
    "print(test_data.shape, summ_stats.shape, y_pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pos = y_pos.reshape((-1,))\n",
    "# print(y_pos)\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "model.eval()\n",
    "summ_stats = torch.Tensor(summ_stats)\n",
    "summ_stats_tensor = summ_stats.to(device)\n",
    "pred = model(summ_stats_tensor)\n",
    "pred = pred.to(\"cpu\").detach().numpy()\n",
    "\n",
    "# print(pred[:, 0].shape)\n",
    "\n",
    "if True:\n",
    "    for i in range(pred.shape[1]):\n",
    "        old_pred = pred[:,i]\n",
    "        label_name = inference_list[i]\n",
    "        min_max_range = ranges[label_name]\n",
    "        org_pred = (((old_pred - feature_range[0]) / (feature_range[1] - feature_range[0])) \n",
    "                    * (min_max_range[1] - min_max_range[0]) + min_max_range[0])\n",
    "        pred[:,i] = org_pred\n",
    "\n",
    "pred[:,0] = y_pos - pred[:, 0]\n",
    "\n",
    "\n",
    "# idx_map = np.stack((np.arange(ids.shape[0]), ids), axis=-1)\n",
    "# idx_map = dict(enumerate(ids.flatten()))\n",
    "# print(ids.flatten())\n",
    "# print(idx_map)\n",
    "        \n",
    "y_pred = pred\n",
    "df = pd.DataFrame(y_pred, columns=inference_list)#.sort_values(by='y')\n",
    "# df = df.rename(index=idx_map)\n",
    "df['cell_id'] = ids.flatten()\n",
    "# df = df[df['y'].between(-700,700)]\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['r_s'] = df['r_s'].clip(ranges['r_s'][0], ranges['r_s'][1])\n",
    "df['l_t'] = df['l_t'].clip(ranges['l_t'][0], ranges['l_t'][1])\n",
    "df['r_t'] = df['r_t'].clip(ranges['r_t'][0], ranges['r_t'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(test_data.shape[1])\n",
    "\n",
    "ix = 1\n",
    "ylim = [-1900,1900]\n",
    "x_dist = np.unique(g_coords[:,0])\n",
    "e_idx = ((g_coords[:,0]==x_dist[ix]) & \n",
    "         (g_coords[:,1]>=ylim[0]) & \n",
    "         (g_coords[:,1]<=ylim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_inference.utils.metrics.prediction_verification import InVivoParamSimulator\n",
    "\n",
    "simu = InVivoParamSimulator(df)\n",
    "lfp, t = simu.verify_and_save(save=False)\n",
    "\n",
    "print(lfp.shape)\n",
    "data_set = []\n",
    "bad_indices = []\n",
    "coordinates = []\n",
    "for i in tqdm(range(lfp.shape[0])):\n",
    "    try:\n",
    "        g_lfp, g_coords, y_i = build_lfp_grid(lfp[i, :, :], params.ELECTRODE_POSITION[:, :2], y_window_size=960.0)\n",
    "    except ValueError:\n",
    "        bad_indices.append(i)\n",
    "        continue\n",
    "    data_set.append(g_lfp)\n",
    "    coordinates.append(g_coords)\n",
    "data_set = np.stack(data_set, axis=0)\n",
    "coordinates = np.stack(coordinates, axis=0)\n",
    "\n",
    "test_data = np.delete(test_data, bad_indices, axis=0)\n",
    "ids = np.delete(ids, bad_indices, axis=0)\n",
    "df = df.drop(index=bad_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "import cell_inference.utils.plotting.plot_results\n",
    "reload(cell_inference.utils.plotting.plot_results)\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "from cell_inference.utils.plotting.plot_results import plot_multiple_lfp_heatmaps\n",
    "\n",
    "\n",
    "for j, (i, row) in enumerate(df.iterrows()):\n",
    "#     if i < 20:\n",
    "#         continue\n",
    "    fig=plt.figure(figsize=(15,4))\n",
    "    outer=GridSpec(1,2)\n",
    "    \n",
    "#     In Vivo Plot\n",
    "    vlim = plot_multiple_lfp_heatmaps(t,\n",
    "                                   coordinates[j, e_idx, 1],\n",
    "                                   np.transpose(test_data[j,:,e_idx]), \n",
    "#                                    savefig='lfp_heatmaps/realinvivo' + str(i) + '.jpg',\n",
    "                                   vlim='auto',\n",
    "                                   fontsize=18,labelpad=0,ticksize=15,nbins=5,\n",
    "                                   fig=fig, outer=outer, col=0, cell_num=0, title='In Vivo Cell {}'.format(row['cell_id']))\n",
    "\n",
    "    # Predicted In Vivo From Params\n",
    "    plot_multiple_lfp_heatmaps(t,\n",
    "                                   coordinates[j, e_idx, 1],\n",
    "                                   np.transpose(data_set[j,:,e_idx]), \n",
    "#                                    savefig='lfp_heatmaps/predictedinvivo' + str(i) + '.jpg',\n",
    "                                   vlim=vlim,\n",
    "                                   fontsize=18,labelpad=0,ticksize=15,nbins=5,\n",
    "                                   fig=fig, outer=outer, col=1, cell_num=0, title='Predicted Cell {}'.format(row['cell_id']))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig('lfp_heatmaps/' + str(row['cell_id']) + '.jpg')\n",
    "#     if i == 22:\n",
    "#         break\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('invivo_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_inference.utils.metrics.corrcoef import corrcoef\n",
    "\n",
    "corrcoef_list = np.array([corrcoef(test_data[i,:,:], data_set[i,:,:]) for i in range(data_set.shape[0])])\n",
    "\n",
    "maidx = np.argmax(corrcoef_list)\n",
    "miidx = np.argmin(corrcoef_list)\n",
    "print('Max Index: {}'.format(maidx))\n",
    "print('Min Index: {}'.format(miidx))\n",
    "\n",
    "plt.hist(corrcoef_list, bins=20)\n",
    "plt.xlabel('Correlation Coefficient')\n",
    "plt.ylabel('Count')\n",
    "plt.title('In Vivo vs Predicted Correlation Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig=plt.figure(figsize=(15,10))\n",
    "\n",
    "for i in [miidx, maidx]:\n",
    "    fig=plt.figure(figsize=(15,4))\n",
    "    outer=GridSpec(1,2)\n",
    "#     print(df.loc[i, 'cell_id'])\n",
    "#     In Vivo Plot\n",
    "    vlim = plot_multiple_lfp_heatmaps(t,\n",
    "                                   coordinates[i, e_idx, 1],\n",
    "                                   np.transpose(test_data[i,:,e_idx]), \n",
    "#                                    savefig='lfp_heatmaps/realinvivo' + str(i) + '.jpg',\n",
    "                                   vlim='auto',\n",
    "                                   fontsize=18,labelpad=0,ticksize=15,nbins=5,\n",
    "                                   fig=fig, outer=outer, col=0, cell_num=0, title='In Vivo Cell {}'.format(df.loc[i, 'cell_id']))\n",
    "\n",
    "    # Predicted In Vivo From Params\n",
    "    plot_multiple_lfp_heatmaps(t,\n",
    "                                   coordinates[i, e_idx, 1],\n",
    "                                   np.transpose(data_set[i,:,e_idx]), \n",
    "#                                    savefig='lfp_heatmaps/predictedinvivo' + str(i) + '.jpg',\n",
    "                                   vlim=vlim,\n",
    "                                   fontsize=18,labelpad=0,ticksize=15,nbins=5,\n",
    "                                   fig=fig, outer=outer, col=1, cell_num=0, title='Predicted Cell {}'.format(df.loc[i, 'cell_id']))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "from importlib import reload\n",
    "# import cell_inference.utils.plotting.plot_all_cells\n",
    "# reload(cell_inference.utils.plotting.plot_all_cells)\n",
    "from cell_inference.utils.plotting.plot_all_cells import plot_all_cells\n",
    "\n",
    "fig, ax = plot_all_cells(df, figsize=(15., 15.))\n",
    "ax.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "LOSS_PATH = 'cell_inference/resources/results/pytorch_losses/13_43_39__02_14_2022.csv'\n",
    "loss_df = pd.read_csv(LOSS_PATH)\n",
    "\n",
    "t_loss = loss_df['Training_Loss'].to_numpy() # / 86729\n",
    "epochs = np.arange(t_loss.shape[0])\n",
    "\n",
    "v_loss = loss_df['Validation_Loss'].to_numpy() # / 28910\n",
    "\n",
    "\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "\n",
    "fig.suptitle(\"Loss Graphs\", fontsize=40)\n",
    "gs=GridSpec(2,2)\n",
    "\n",
    "ax1=fig.add_subplot(gs[0,:]) \n",
    "ax2=fig.add_subplot(gs[1,0]) \n",
    "ax3=fig.add_subplot(gs[1,1]) \n",
    "\n",
    "ax1.plot(epochs, t_loss, label='Training Loss')\n",
    "ax1.plot(epochs, v_loss, label='Validation Loss')\n",
    "ax1.tick_params(labelsize=20)\n",
    "ax1.set_ylim(bottom=15, top=120)\n",
    "# ax1.set_xlabel('Epoch', fontsize=40)\n",
    "ax1.set_ylabel('Loss', fontsize=30)\n",
    "ax1.legend(fontsize=15)\n",
    "\n",
    "ax2.plot(epochs, t_loss, label='Training Loss')\n",
    "ax2.tick_params(labelsize=20)\n",
    "ax2.set_ylim(bottom=40, top=120)\n",
    "ax2.set_xlabel('Epoch', fontsize=30)\n",
    "ax2.set_ylabel('Loss', fontsize=30)\n",
    "ax2.set_title('Training', fontsize=20)\n",
    "\n",
    "ax3.plot(epochs, v_loss, label='Validation Loss')\n",
    "ax3.tick_params(labelsize=20)\n",
    "ax3.set_xlabel('Epoch', fontsize=30)\n",
    "ax3.set_title('Validation', fontsize=20)\n",
    "# ax3.set_ylabel('Loss', fontsize=40)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# print(t_loss)\n",
    "# display(loss_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
