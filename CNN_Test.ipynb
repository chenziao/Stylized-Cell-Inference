{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ac31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from typing import Optional, Union, Tuple, List\n",
    "from enum import Enum\n",
    "\n",
    "class ActivationTypes(Enum):\n",
    "    ReLU = 1\n",
    "    TanH = 2\n",
    "    Sigmoid = 3\n",
    "    LeakyReLU = 4\n",
    "\n",
    "activation_mapping = {\n",
    "    ActivationTypes.ReLU: nn.ReLU,\n",
    "    ActivationTypes.TanH: nn.Tanh,\n",
    "    ActivationTypes.Sigmoid: nn.Sigmoid,\n",
    "    ActivationTypes.LeakyReLU: nn.LeakyReLU,\n",
    "    None: nn.ReLU\n",
    "}\n",
    "\n",
    "class ConvolutionalNetwork(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_features: int, num_filters: Optional[Union[Tuple, List]]=None,\n",
    "                 activation: Optional[ActivationTypes] = None) -> None:\n",
    "        super(ConvolutionalNetwork, self).__init__()\n",
    "\n",
    "        self.activation = activation_mapping[activation]\n",
    "\n",
    "        n_channels = [16, 32, 64, 128, 128, 256, 256, 256, 64, 8]\n",
    "        if num_filters is not None:\n",
    "            n = len(n_channels)\n",
    "            if not hasattr(num_filters, '__len__'):\n",
    "                num_filters = [num_filters] * n\n",
    "            for i in range(min(len(num_filters), n)):\n",
    "                n_channels[i] = num_filters[i]\n",
    "\n",
    "        n = 0 # number of layers\n",
    "        # 3D convolutional block\n",
    "        conv1 = []\n",
    "        # input (samp, chan, T, X, Y) ==> (N, 2, 144, 4, 99)\n",
    "        conv1.append(nn.Conv3d(in_channels=in_channels, out_channels=n_channels[0], \n",
    "                               kernel_size=(1, 3, 3), padding=(0, 1, 1), padding_mode='replicate'))\n",
    "        # (N, 16, 144, 4, 99), downsample X\n",
    "        conv1.append(nn.Conv3d(in_channels=n_channels[0], out_channels=n_channels[1], \n",
    "                               kernel_size=(3, 3, 3), padding=(1, 0, 0), padding_mode='replicate'))\n",
    "        # (N, 32, 144, 2, 97), downsample T\n",
    "        conv1.append(nn.Conv3d(in_channels=n_channels[1], out_channels=n_channels[2], \n",
    "                               kernel_size=(3, 2, 3), stride=(2, 1, 1), padding=(0, 0, 0), padding_mode='replicate'))\n",
    "        # (N, 64, 71, 1, 95), dimension reduction\n",
    "        conv1_dict = OrderedDict()\n",
    "        for i, x in enumerate(conv1):\n",
    "            conv1_dict['conv' + str(n + i)] = x\n",
    "            conv1_dict['actv' + str(n + i)] = self.activation()\n",
    "        self.conv3d_block = nn.Sequential(conv1_dict)\n",
    "        n += len(conv1)\n",
    "\n",
    "        # 2D convolutional block\n",
    "        conv2 = []\n",
    "        #(N, 64, 71, 95), downsample\n",
    "        conv2.append(nn.Conv2d(in_channels=n_channels[2], out_channels=n_channels[3], \n",
    "                               kernel_size=(3, 3), stride=2))\n",
    "        #(N, 128, 35, 47), conv\n",
    "        conv2.append(nn.Conv2d(in_channels=n_channels[3], out_channels=n_channels[4], \n",
    "                               kernel_size=(3, 3), padding=(1, 1), padding_mode='replicate'))\n",
    "        #(N, 128, 35, 47), downsample\n",
    "        conv2.append(nn.Conv2d(in_channels=n_channels[4], out_channels=n_channels[5], \n",
    "                               kernel_size=(3, 3), stride=2))\n",
    "        #(N, 256, 17, 23), conv\n",
    "        conv2.append(nn.Conv2d(in_channels=n_channels[5], out_channels=n_channels[6], \n",
    "                               kernel_size=(3, 3), padding=(0, 0), padding_mode='replicate'))\n",
    "        #(N, 256, 15, 21), downsample\n",
    "        conv2.append(nn.Conv2d(in_channels=n_channels[6], out_channels=n_channels[7], \n",
    "                               kernel_size=(3, 3), stride=2))\n",
    "        #(N, 256, 7, 10)\n",
    "        conv2_dict = OrderedDict()\n",
    "        for i, x in enumerate(conv2):\n",
    "            conv2_dict['conv' + str(n + i)] = x\n",
    "            conv2_dict['actv' + str(n + i)] = self.activation()\n",
    "        self.conv2d_block = nn.Sequential(conv2_dict)\n",
    "        n += len(conv2)\n",
    "\n",
    "        # 1x1 convolutional block\n",
    "        conv3 = []\n",
    "        #(N, 256, 7, 10)\n",
    "        conv3.append(nn.Conv2d(in_channels=n_channels[7], out_channels=n_channels[8], kernel_size=(1, 1)))\n",
    "        #(N, 64, 7, 10)\n",
    "        conv3.append(nn.Conv2d(in_channels=n_channels[8], out_channels=n_channels[9], kernel_size=(1, 1)))\n",
    "        #(N, 8, 7, 10)\n",
    "        conv3_dict = OrderedDict()\n",
    "        for i, x in enumerate(conv3):\n",
    "            conv3_dict['conv' + str(n + i)] = x\n",
    "            conv3_dict['actv' + str(n + i)] = self.activation()\n",
    "        self.conv1x1_block = nn.Sequential(conv3_dict)\n",
    "        n += len(conv3)\n",
    "\n",
    "        linear = []\n",
    "        linear.append(nn.Linear(7 * 10 * n_channels[9], 128))\n",
    "        linear.append(nn.Linear(128, 32))\n",
    "        linear.append(nn.Linear(32, out_features))\n",
    "        linear_dict = OrderedDict()\n",
    "        for i, x in enumerate(linear[:-1]):\n",
    "            linear_dict['linear' + str(n + i)] = x\n",
    "            linear_dict['actv' + str(n + i)] = self.activation()\n",
    "        n += len(linear)\n",
    "        linear_dict['linear' + str(n - 1)] = linear[-1]\n",
    "        self.linear_block = nn.Sequential(linear_dict)\n",
    "\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # print(\"Input Shape: {}\".format(x.shape))\n",
    "        x = self.conv3d_block(x)\n",
    "        # print(\"First Shape: {}\".format(x.shape))\n",
    "        \n",
    "        x = x.squeeze(dim=3) # dimension reduction\n",
    "        # print(\"Squeezed Shape: {}\".format(x.shape))\n",
    "        x = self.conv2d_block(x)\n",
    "        # print(\"Second Shape: {}\".format(x.shape))\n",
    "        \n",
    "        x = self.conv1x1_block(x)\n",
    "        # print(\"Third Shape: {}\".format(x.shape))\n",
    "        \n",
    "        x = x.view(x.shape[0], -1) # Flattening\n",
    "        x = self.linear_block(x)\n",
    "        # print(\"Final Shape: {}\".format(x.shape))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db0dd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutionalNetwork(\n",
       "  (conv3d_block): Sequential(\n",
       "    (conv0): Conv3d(2, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), padding_mode=replicate)\n",
       "    (actv0): ReLU()\n",
       "    (conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 0, 0), padding_mode=replicate)\n",
       "    (actv1): ReLU()\n",
       "    (conv2): Conv3d(32, 64, kernel_size=(3, 2, 3), stride=(2, 1, 1), padding_mode=replicate)\n",
       "    (actv2): ReLU()\n",
       "  )\n",
       "  (conv2d_block): Sequential(\n",
       "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (actv3): ReLU()\n",
       "    (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), padding_mode=replicate)\n",
       "    (actv4): ReLU()\n",
       "    (conv5): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (actv5): ReLU()\n",
       "    (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding_mode=replicate)\n",
       "    (actv6): ReLU()\n",
       "    (conv7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (actv7): ReLU()\n",
       "  )\n",
       "  (conv1x1_block): Sequential(\n",
       "    (conv8): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (actv8): ReLU()\n",
       "    (conv9): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (actv9): ReLU()\n",
       "  )\n",
       "  (linear_block): Sequential(\n",
       "    (linear10): Linear(in_features=560, out_features=128, bias=True)\n",
       "    (actv10): ReLU()\n",
       "    (linear11): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (actv11): ReLU()\n",
       "    (linear12): Linear(in_features=32, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvolutionalNetwork(in_channels=2, out_features=7)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9276d747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.08835803,  0.15647157,  0.07602078, -0.12569493,  0.16587344,\n",
       "         0.10741543,  0.00880771]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.randn(10, 2, 144, 4, 99)\n",
    "\n",
    "Y = model(torch.Tensor(X).to(device)).to(\"cpu\").detach().numpy()\n",
    "\n",
    "model(torch.Tensor(X[0]).unsqueeze(0).to(device)).to(\"cpu\").detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e4ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
