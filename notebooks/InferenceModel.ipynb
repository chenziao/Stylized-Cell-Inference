{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## INFERENCE MODEL\n",
    "Setup inference model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os, sys\r\n",
    "sys.path.append(os.path.split(sys.path[0])[0])\r\n",
    "\r\n",
    "#Dependencies\r\n",
    "import dill\r\n",
    "import h5py\r\n",
    "import math\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pickle\r\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\r\n",
    "import sbi.analysis as analysis\r\n",
    "import sbi.utils as utils\r\n",
    "from sbi.utils.get_nn_models import posterior_nn  # For SNLE: likelihood_nn(). For SNRE: classifier_nn()\r\n",
    "from scipy import signal, stats as spstats\r\n",
    "import scipy.io\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "#Project Imports\r\n",
    "import config.params as params\r\n",
    "import config.paths as paths\r\n",
    "from stylized_module.base.passive_model_soma_injection import run_pm_simulation\r\n",
    "from stylized_module.base.active_model_synapse_input import run_am_simulation\r\n",
    "from stylized_module.models.cnn import SummaryNet\r\n",
    "from stylized_module.models.SummaryStats1D import Stats, cat_output\r\n",
    "from utils.metrics.corrcoef import corrcoef, max_corrcoef\r\n",
    "from utils.plotting.plot_results import plot_LFP_traces,plot_LFP_heatmap\r\n",
    "from utils.spike_window import first_pk_tr, get_spike_window\r\n",
    "from utils.transform.distribution_transformation import norm2unif, range2logn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Helper Functions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "rng = np.random.default_rng(123412)\r\n",
    "\r\n",
    "def passive_model(param,whole_trace=False):\r\n",
    "    #Replace theta with random number\r\n",
    "    theta = [rng.uniform(low=params.IM_THETA_BOUNDS[0], high=params.IM_THETA_BOUNDS[1])]\r\n",
    "    sim.set_loc_param(torch.cat((torch.zeros(1),param[:2], torch.tensor(theta), param[2:4])))\r\n",
    "    scalVal = 1 #10 ** param[5]\r\n",
    "    sim.set_scale(scalVal)\r\n",
    "    sim.set_geo_param(param[4:])\r\n",
    "    sim.create_cells()\r\n",
    "    sim.run()\r\n",
    "    lfp = sim.get_lfp().T\r\n",
    "    filtered_lfp = signal.lfilter(filt_b,filt_a,lfp,axis=0) # filter along row of the lfp 2d-array, if each row is a channel\r\n",
    "    if not whole_trace:\r\n",
    "        start,end = get_spike_window(filtered_lfp,win_size=params.PM_WINDOW_SIZE,align_at=fst_idx)\r\n",
    "        filtered_lfp = filtered_lfp[start:end,:]\r\n",
    "    return filtered_lfp\r\n",
    "\r\n",
    "def active_model(param,whole_trace=False):\r\n",
    "#     biophys = [param[0],-1,-1,param[1],-1,param[2],-1]\r\n",
    "#     sim.set_biophys(biophys)\r\n",
    "    \r\n",
    "    #Replace theta with random number\r\n",
    "    theta = [rng.uniform(low=params.IM_THETA_BOUNDS[0], high=params.IM_THETA_BOUNDS[1])]\r\n",
    "#     print(np.squeeze(param).shape)\r\n",
    "    if param.size()[1] is not None:\r\n",
    "        sim.set_loc_param(torch.cat((torch.zeros(1), \r\n",
    "                                    norm2unif([0,1], param[0][0], param[0][1]), \r\n",
    "                                    norm2unif([0,1], param[1][0], param[1][1]),\r\n",
    "                                    torch.tensor(theta), \r\n",
    "                                    norm2unif([0,1], param[2][0], param[2][1]),\r\n",
    "                                    norm2unif([0,1], param[3][0], param[3][1]))))\r\n",
    "                                    \r\n",
    "        sim.set_geo_param(torch.cat((range2logn(param[4][0], param[4][1]),\r\n",
    "                                    range2logn(param[5][0], param[5][1]),\r\n",
    "                                    range2logn(param[6][0], param[6][1]),\r\n",
    "                                    range2logn(param[7][0], param[7][1]),\r\n",
    "                                    range2logn(param[8][0], param[8][1]),\r\n",
    "                                    range2logn(param[9][0], param[9][1]))))\r\n",
    "    else:\r\n",
    "        sim.set_loc_param(torch.cat((torch.zeros(1),param[:2], torch.tensor(theta), param[2:4])))\r\n",
    "        sim.set_geo_param(param[4:])\r\n",
    "        \r\n",
    "    scalVal = 1 #10 ** param[5]\r\n",
    "    sim.set_scale(scalVal)\r\n",
    "    \r\n",
    "    sim.set_gmax(params.GT_GMAX)\r\n",
    "#     scalVal = 10 ** param[4]\r\n",
    "    sim.set_scale(scalVal)\r\n",
    "    sim.create_cells()\r\n",
    "    sim.run()\r\n",
    "    lfp = sim.get_lfp().T\r\n",
    "    filtered_lfp = signal.lfilter(filt_b,filt_a,lfp,axis=0) # filter along row of the lfp 2d-array, if each row is a channel\r\n",
    "    if not whole_trace:\r\n",
    "        start,end = get_spike_window(filtered_lfp,win_size=params.AM_WINDOW_SIZE,align_at=fst_idx)\r\n",
    "        filtered_lfp = filtered_lfp[start:end,:]\r\n",
    "    return filtered_lfp\r\n",
    "\r\n",
    "# def Stats(lfp):\r\n",
    "#     \"\"\"\r\n",
    "#     Calculates summary statistics\r\n",
    "#     results = model(params)\r\n",
    "#     \"\"\"\r\n",
    "#     lfp = np.asarray(lfp)\r\n",
    "    \r\n",
    "#     avg = np.mean(lfp,axis=0) # average voltage of each channel\r\n",
    "# #     stdDev = np.std(lfp,axis=0) # stDev of the voltage of each channel\r\n",
    "#     tT = np.argmin(lfp,axis=0)\r\n",
    "#     tP = np.argmax(lfp,axis=0)\r\n",
    "#     Troughs = np.take_along_axis(lfp,np.expand_dims(tT,axis=0),axis=0)\r\n",
    "#     Peaks = np.take_along_axis(lfp,np.expand_dims(tP,axis=0),axis=0)\r\n",
    "#     relT = tP-tT\r\n",
    "#     stats_list = [avg,Troughs,Peaks,relT]\r\n",
    "    \r\n",
    "#     def statscalc(stats):\r\n",
    "#         stats = stats.ravel()\r\n",
    "#         mean = np.mean(stats)\r\n",
    "#         std = np.std(stats)\r\n",
    "#         m = np.argmin(stats)\r\n",
    "#         min_pos = params.IM_Y_DISTANCE[m]\r\n",
    "#         min_val = stats[m]\r\n",
    "#         M = np.argmax(stats)\r\n",
    "#         max_pos = params.IM_Y_DISTANCE[M] \r\n",
    "#         max_val = stats[M]\r\n",
    "#         All = np.array([mean,std,min_pos,min_val,max_pos,max_val])\r\n",
    "#         return All\r\n",
    "    \r\n",
    "#     allStats = np.concatenate([statscalc(x) for x in stats_list])\r\n",
    "#     return allStats\r\n",
    "\r\n",
    "# def cat_output(lfp):\r\n",
    "#     output = np.concatenate((lfp.ravel(),Stats(lfp)))\r\n",
    "#     return torch.from_numpy(output)\r\n",
    "\r\n",
    "def simulation(sim_params):\r\n",
    "    lfp = passive_model(sim_params) if params.ACTIVE_CELL is False else active_model(sim_params)\r\n",
    "    return cat_output(lfp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "filt_b,filt_a = signal.butter(params.IM_BUTTERWORTH_ORDER,\r\n",
    "                              params.IM_CRITICAL_FREQUENCY,\r\n",
    "                              params.IM_BANDFILTER_TYPE,\r\n",
    "                              fs=params.IM_FILTER_SAMPLING_RATE)\r\n",
    "\r\n",
    "sim, window_size, x0_trace, t0 = run_pm_simulation() if params.ACTIVE_CELL is False else run_am_simulation()\r\n",
    "\r\n",
    "fst_idx = first_pk_tr(x0_trace)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "simulator, prior = prepare_for_sbi(simulation, params.IM_PRIOR_DISTRIBUTION)\r\n",
    "x_o = cat_output(x0_trace)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# instantiate the neural density estimator\r\n",
    "density_estimator_build_fun = posterior_nn(model=params.IM_POSTERIOR_MODEL_ESTIMATOR,\r\n",
    "                                           embedding_net=params.IM_EMBEDDED_NETWORK,\r\n",
    "                                           hidden_features=params.IM_POSTERIOR_MODEL_HIDDEN_LAYERS)\r\n",
    "\r\n",
    "inference = SNPE(prior=prior,density_estimator=density_estimator_build_fun,show_progress_bars=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "posteriors = []\r\n",
    "proposal = prior\r\n",
    "\r\n",
    "for i in range(params.IM_NUMBER_OF_ROUNDS):\r\n",
    "    print(type(simulator))\r\n",
    "    print(type(proposal))\r\n",
    "    theta, x = simulate_for_sbi(simulator,proposal,num_simulations=params.IM_NUMBER_OF_SIMULATIONS)\r\n",
    "     # In `SNLE` and `SNRE`, you should not pass the `proposal` to `.append_simulations()`\r\n",
    "#     density_estimator = inference.append_simulations(np.squeeze(theta), np.squeeze(x), proposal=proposal).train()\r\n",
    "    density_estimator = inference.append_simulations(np.squeeze(theta), x, proposal=proposal).train()\r\n",
    "    posterior = inference.build_posterior(density_estimator, sample_with=\"mcmc\")\r\n",
    "    \r\n",
    "    with open(paths.POSTERIOR_SAVE + str(i) + \"_post.pkl\", \"wb\") as handle:\r\n",
    "        pickle.dump(posterior, handle)\r\n",
    "        \r\n",
    "    with open(paths.POSTERIOR_SAVE + str(i) + \"_de.pkl\", \"wb\") as handle:\r\n",
    "        pickle.dump(density_estimator, handle)\r\n",
    "        \r\n",
    "    posteriors.append(posterior)\r\n",
    "    proposal = posterior.set_default_x(x_o)\r\n",
    "    \r\n",
    "inference._summary_writer = None\r\n",
    "inference._build_neural_net = None\r\n",
    "with open(paths.INFERENCER_SAVE + str(i) + \".pkl\", \"wb\") as handle:\r\n",
    "    pickle.dump(inference, handle)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'function'>\n",
      "<class 'stylized_module.dists.distributions.StackedDistribution'>\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0ff0ef592240358cb8d13a0e3be42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 5000 simulations.:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Neural network successfully converged after 352 epochs.\n",
      "<class 'function'>\n",
      "<class 'sbi.inference.posteriors.direct_posterior.DirectPosterior'>\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NotImplementedError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-02f934d10534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulate_for_sbi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_simulations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIM_NUMBER_OF_SIMULATIONS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m      \u001b[0;31m# In `SNLE` and `SNRE`, you should not pass the `proposal` to `.append_simulations()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     density_estimator = inference.append_simulations(np.squeeze(theta), np.squeeze(x), proposal=proposal).train()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venvs/sbi/lib/python3.8/site-packages/sbi/inference/base.py\u001b[0m in \u001b[0;36msimulate_for_sbi\u001b[0;34m(simulator, proposal, num_simulations, num_workers, simulation_batch_size, show_progress_bar)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0mcheck_if_proposal_has_default_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproposal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m     \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproposal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_simulations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     x = simulate_in_batches(\n",
      "\u001b[0;32m~/venvs/sbi/lib/python3.8/site-packages/sbi/inference/posteriors/direct_posterior.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape, x, show_progress_bars, sample_with, mcmc_method, mcmc_parameters, rejection_sampling_parameters, sample_with_mcmc)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mmcmc_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcmc_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             )\n\u001b[0;32m--> 352\u001b[0;31m             transform = mcmc_transform(\n\u001b[0m\u001b[1;32m    353\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmcmc_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             )\n",
      "\u001b[0;32m~/venvs/sbi/lib/python3.8/site-packages/sbi/utils/sbiutils.py\u001b[0m in \u001b[0;36mmcmc_transform\u001b[0;34m(prior, num_prior_samples_for_zscoring, enable_transform, device, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0menable_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         if hasattr(prior.support, \"base_constraint\") and hasattr(\n\u001b[0m\u001b[1;32m    919\u001b[0m             \u001b[0mprior\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_constraint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"upper_bound\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         ):\n",
      "\u001b[0;32m~/venvs/sbi/lib/python3.8/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36msupport\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mrepresenting\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0msupport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "samples = posterior.sample((1000,), x=x_o, sample_with_mcmc=True) #, sample_with_mcmc=True\n",
    "\n",
    "#posterior.leakage_correction(x_o, num_rejection_samples=1000)\n",
    "log_probability = posterior.log_prob(samples,x=x_o, norm_posterior=False) #, norm_posterior=False\n",
    "plt.hist(log_probability.numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sample_idx = np.argmax(log_probability)\n",
    "predicted_post = samples[sample_idx]\n",
    "predicted_post"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "save_xo = params.IM_SAVE_X0\n",
    "# save_xo = 'x_0_traces.pdf'\n",
    "fig,ax = plot_LFP_traces(t0,x0_trace,savefig=params.IM_SAVE_X0)\n",
    "# save_xo = 'x_0_HTmap.pdf'\n",
    "elec_idx = slice(30,-10)\n",
    "fig,ax = plot_LFP_heatmap(t0,params.IM_Y_DISTANCE[elec_idx],x0_trace[:,elec_idx],vlim='auto',savefig=params.IM_SAVE_X0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# predicted_lfp = passive_model(params.IM_RANDOM_SAMPLE,whole_trace=True)\n",
    "predicted_lfp = passive_model(predicted_post,whole_trace=True) if params.ACTIVE_CELL is False else active_model(predicted_post, whole_trace=True)\n",
    "\n",
    "fig,ax = plot_LFP_traces(sim.t(),predicted_lfp)\n",
    "start,end = get_spike_window(predicted_lfp,win_size=params.PM_WINDOW_SIZE,align_at=fst_idx)\n",
    "predicted_lfp_win = predicted_lfp[start:end,:]\n",
    "\n",
    "savefig = paths.PASSIVE_INFERENCE_SAVE_TRACES if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_SAVE_TRACES\n",
    "fig,ax = plot_LFP_traces(t0,\n",
    "                         predicted_lfp_win,\n",
    "                         savefig=savefig)\n",
    "\n",
    "savefig = paths.PASSIVE_INFERENCE_SAVE_HEATMAPS if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_SAVE_HEATMAPS\n",
    "fig,ax = plot_LFP_heatmap(t0,\n",
    "                          params.IM_Y_DISTANCE[elec_idx],\n",
    "                          predicted_lfp_win[:,elec_idx],\n",
    "                          vlim='auto',\n",
    "                          savefig=savefig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max_corr, max_ind = max_corrcoef(x0_trace,predicted_lfp)\n",
    "print(max_corr,max_ind)\n",
    "max_corr, max_ind = max_corrcoef(x0_trace,predicted_lfp_win)\n",
    "print(max_corr,max_ind)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "hf_file = paths.PASSIVE_INFERENCE_RESULTS_DATA if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_RESULTS_DATA\n",
    "hf = h5py.File(hf_file, 'w')\n",
    "hf.create_dataset('LFP',data=predicted_lfp)\n",
    "hf.create_dataset('samples',data=samples.numpy())\n",
    "hf.create_dataset('log_prob',data=log_probability.numpy())\n",
    "hf.close()\n",
    "\n",
    "mat_file = paths.PASSIVE_INFERENCE_RESULTS_MATLAB_DATA if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_RESULTS_MATLAB_DATA\n",
    "scipy.io.savemat(mat_file,\n",
    "                 {'LFP':predicted_lfp_win[:,elec_idx],'t':t0,'y_dist':params.IM_Y_DISTANCE[elec_idx]})\n",
    "\n",
    "mat_file = paths.PASSIVE_INFERENCE_RESULTS_X0_MATLAB_DATA if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_RESULTS_X0_MATLAB_DATA\n",
    "scipy.io.savemat(mat_file,\n",
    "                 {'LFP':x0_trace[:,elec_idx],'t':t0,'y_dist':params.IM_Y_DISTANCE[elec_idx]})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels_params = params.IM_GRAPHING_LABELS\n",
    "fig, axes = analysis.pairplot(samples,\n",
    "                           limits = params.IM_PARAMETER_BOUNDS,\n",
    "                           ticks = params.IM_PARAMETER_BOUNDS,\n",
    "                           figsize=(12,12),\n",
    "                           #points=true_params,\n",
    "                           points_offdiag={'markersize': 6},\n",
    "                           labels = params.IM_GRAPHING_LABELS,\n",
    "                           points_colors='r');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\n",
    "\n",
    "labels_params = params.IM_GRAPHING_LABELS\n",
    "bounds_ticks = params.IM_PARAMETER_BOUNDS\n",
    "bounds_ticks[2] = bounds_ticks[4] = [0,3.14]\n",
    "fig, axes = analysis.pairplot(samples,\n",
    "                           limits = params.IM_PARAMETER_BOUNDS,\n",
    "                           ticks = params.IM_PARAMETER_BOUNDS,\n",
    "                           figsize=(25,25),\n",
    "                           #points=true_params,\n",
    "                           points_offdiag={'markersize': 6},\n",
    "                           labels = params.IM_GRAPHING_LABELS,\n",
    "                           points_colors='r');\n",
    "\n",
    "# axes[4][4].set_xlabel('\\u03BB',fontsize = 40)\n",
    "for i in range(len(params.IM_PARAMETER_BOUNDS)):\n",
    "    axes[i][i].tick_params('x',labelsize=15)\n",
    "    axes[i][i].xaxis.label.set_fontsize(40)\n",
    "\n",
    "for i,b in enumerate(params.IM_PARAMETER_BOUNDS):\n",
    "    axes[i][i].set_xticklabels([str(b[0]),str(b[1])],fontsize=30)\n",
    "\n",
    "    \n",
    "save_file = paths.PASSIVE_INFERENCE_SAVE_KDE if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_SAVE_KDE\n",
    "plt.savefig(save_file,bbox_inches='tight',transparent=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}