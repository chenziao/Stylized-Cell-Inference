{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "animated-third",
   "metadata": {},
   "source": [
    "## INFERENCE MODEL\n",
    "Setup inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fundamental-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.split(sys.path[0])[0])\n",
    "\n",
    "#Dependencies\n",
    "import h5py\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "import sbi.analysis as analysis\n",
    "from sbi.utils.get_nn_models import posterior_nn  # For SNLE: likelihood_nn(). For SNRE: classifier_nn()\n",
    "from scipy import signal, stats as spstats\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Project Imports\n",
    "import config.params as params\n",
    "import config.paths as paths\n",
    "from stylized_module.base.passive_model_soma_injection import run_pm_simulation\n",
    "from stylized_module.base.active_model_synapse_input import run_am_simulation\n",
    "from stylized_module.models.SummaryStats2D import Stats, cat_output\n",
    "from utils.metrics.corrcoef import corrcoef, max_corrcoef\n",
    "from utils.plotting.plot_results import plot_LFP_traces,plot_LFP_heatmap\n",
    "from utils.spike_window import first_pk_tr, get_spike_window\n",
    "from utils.transform.distribution_transformation import norm2unif, range2logn, norm2logn, logds_norm2unif, logds_norm2logn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-prince",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "canadian-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(123412)\n",
    "\n",
    "def passive_model(param,whole_trace=False):\n",
    "    #Replace theta with random number\n",
    "    theta = [rng.uniform(low=params.IM_THETA_BOUNDS[0], high=params.IM_THETA_BOUNDS[1])]\n",
    "    sim.set_loc_param(torch.cat((torch.zeros(1),param[:2], torch.tensor(theta), param[2:4])))\n",
    "    scalVal = 1 #10 ** param[5]\n",
    "    sim.set_scale(scalVal)\n",
    "    sim.set_geo_param(param[4:])\n",
    "    sim.create_cells()\n",
    "    sim.run()\n",
    "    lfp = sim.get_lfp().T\n",
    "    filtered_lfp = signal.lfilter(filt_b,filt_a,lfp,axis=0) # filter along row of the lfp 2d-array, if each row is a channel\n",
    "    if not whole_trace:\n",
    "        start,end = get_spike_window(filtered_lfp,win_size=params.PM_WINDOW_SIZE,align_at=fst_idx)\n",
    "        filtered_lfp = filtered_lfp[start:end,:]\n",
    "    return filtered_lfp\n",
    "\n",
    "def active_model(param,whole_trace=False):\n",
    "#     biophys = [param[0],-1,-1,param[1],-1,param[2],-1]\n",
    "#     sim.set_biophys(biophys)\n",
    "    \n",
    "    #Replace alpha with random number\n",
    "    alpha = rng.uniform(low=params.IM_ALPHA_BOUNDS[0], high=params.IM_ALPHA_BOUNDS[1])\n",
    "    d = param[1],\n",
    "    theta = param[2],\n",
    "    x = d * np.sin(theta)\n",
    "    z = d * np.cos(theta)\n",
    "    \n",
    "    numpy_list = np.squeeze(np.array([\n",
    "        x, #x\n",
    "        [param[0]], #y\n",
    "        z, #z\n",
    "        [alpha], #alpha\n",
    "        [param[3]], #h\n",
    "        [param[4]], #phi\n",
    "    ]))\n",
    "#     print(numpy_list)\n",
    "    sim.set_loc_param(torch.from_numpy(numpy_list))\n",
    "    \n",
    "    geo_list = np.array([\n",
    "        param[5],\n",
    "        param[6],\n",
    "        param[7],\n",
    "        param[8],\n",
    "        param[9],\n",
    "        param[10]\n",
    "    ])\n",
    "\n",
    "    sim.set_geo_param(torch.from_numpy(geo_list))\n",
    "\n",
    "    scalVal = 1 #10 ** param[5]\n",
    "    sim.set_scale(scalVal)\n",
    "    \n",
    "    sim.set_gmax(params.GT_GMAX)\n",
    "#     scalVal = 10 ** param[4]\n",
    "    sim.set_scale(scalVal)\n",
    "    sim.create_cells()\n",
    "    sim.run()\n",
    "    lfp = sim.get_lfp().T\n",
    "    filtered_lfp = signal.lfilter(filt_b,filt_a,lfp,axis=0) # filter along row of the lfp 2d-array, if each row is a channel\n",
    "    if not whole_trace:\n",
    "        start,end = get_spike_window(filtered_lfp,win_size=params.AM_WINDOW_SIZE,align_at=fst_idx)\n",
    "        filtered_lfp = filtered_lfp[start:end,:]\n",
    "    return filtered_lfp\n",
    "\n",
    "\n",
    "def simulation(sim_params):\n",
    "    lfp = passive_model(sim_params) if params.ACTIVE_CELL is False else active_model(sim_params)\n",
    "    return cat_output(lfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "instrumental-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_b,filt_a = signal.butter(params.IM_BUTTERWORTH_ORDER,\n",
    "                              params.IM_CRITICAL_FREQUENCY,\n",
    "                              params.IM_BANDFILTER_TYPE,\n",
    "                              fs=params.IM_FILTER_SAMPLING_RATE)\n",
    "\n",
    "sim, window_size, x0_trace, t0 = run_pm_simulation() if params.ACTIVE_CELL is False else run_am_simulation()\n",
    "\n",
    "fst_idx = first_pk_tr(x0_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "induced-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([72991])\n"
     ]
    }
   ],
   "source": [
    "simulator, prior = prepare_for_sbi(simulation, params.IM_PRIOR_DISTRIBUTION)\n",
    "x_o = cat_output(x0_trace)\n",
    "print(x_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exterior-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the neural density estimator\n",
    "density_estimator_build_fun = posterior_nn(\n",
    "    model=params.IM_POSTERIOR_MODEL_ESTIMATOR,\n",
    "    embedding_net=params.IM_EMBEDDED_NETWORK,\n",
    "    hidden_features=params.IM_POSTERIOR_MODEL_HIDDEN_LAYERS\n",
    ")\n",
    "\n",
    "inference = SNPE(\n",
    "    prior=prior,\n",
    "    density_estimator=density_estimator_build_fun,\n",
    "    show_progress_bars=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-billion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a56a82ae1a7496da7fd2203d7ee0f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 1000 simulations.:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network successfully converged after 140 epochs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3038e782afb47689a878233fc6783f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [1]:   0%|          | 0/134 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ef13f90c904347996658af9bd17bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [2]:   0%|          | 0/134 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18bb5050ade4854adcd8576a016dc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [3]:   0%|          | 0/134 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c151ea9c89743b09b8bcfad4c95dec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [4]:   0%|          | 0/134 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddd2665a2c14f5686d569792e86b9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [5]:   0%|          | 0/134 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8cba87bfe74b759c6728c4f5280c9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [6]:   0%|          | 0/134 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab60d153e3014457b44be990913e985e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [7]:   0%|          | 0/134 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5516cedea08d48068569fd9ac5ebddcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Warmup [8]:   0%|          | 0/134 [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f33d7b280a419190e2c8aa10188538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 1000 simulations.:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "posteriors = []\n",
    "proposal = prior\n",
    "\n",
    "for i in range(params.IM_NUMBER_OF_ROUNDS):\n",
    "    if i == 0:\n",
    "        theta = np.load(\"theta_pyro_0.npy\")\n",
    "        x = np.load(\"x_pyro_0.npy\")\n",
    "    else:\n",
    "        theta, x = simulate_for_sbi(\n",
    "            simulator,\n",
    "            proposal,\n",
    "            num_simulations=params.IM_NUMBER_OF_SIMULATIONS\n",
    "        )\n",
    "\n",
    "    np.save(\"theta_pyro_\" + str(i) + \".npy\", theta)\n",
    "    np.save(\"x_pyro_\" + str(i) + \".npy\", x)\n",
    "    \n",
    "        \n",
    "     # In `SNLE` and `SNRE`, you should not pass the `proposal` to `.append_simulations()`\n",
    "#     density_estimator = inference.append_simulations(np.squeeze(theta), np.squeeze(x), proposal=proposal).train()\n",
    "    density_estimator = inference.append_simulations(np.squeeze(theta), x, proposal=proposal).train()\n",
    "    \n",
    "    posterior = inference.build_posterior(\n",
    "        density_estimator, \n",
    "        sample_with=\"mcmc\", \n",
    "        mcmc_method=\"hmc\", \n",
    "        mcmc_parameters={'num_chains': 8, 'thin': 1, 'warmup_steps': 1}\n",
    "    )\n",
    "    \n",
    "    with open(paths.POSTERIOR_SAVE + str(i) + \"_pyro_post.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(posterior, handle)\n",
    "        \n",
    "    with open(paths.POSTERIOR_SAVE + str(i) + \"_pyro_de.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(density_estimator, handle)\n",
    "        \n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(x_o)\n",
    "    \n",
    "inference._summary_writer = None\n",
    "inference._build_neural_net = None\n",
    "with open(paths.INFERENCER_SAVE + str(i) + \"_pyro.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(inference, handle)\n",
    "\n",
    "# with open(paths.POSTERIOR_SAVE + \"2_post.pkl\", \"rb\") as handle:\n",
    "#     posterior = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = posterior.sample((1000,), x=x_o)#, sample_with='mcmc') #, sample_with_mcmc=True\n",
    "samples = posterior.sample(\n",
    "    (1000,), \n",
    "    x=x_o, \n",
    "    sample_with='mcmc',\n",
    "    mcmc_method=\"hmc\", \n",
    "    mcmc_parameters={'num_chains': 8, 'thin': 1, 'warmup_steps': 1}\n",
    ")\n",
    "\n",
    "#posterior.leakage_correction(x_o, num_rejection_samples=1000)\n",
    "log_probability = posterior.log_prob(samples,x=x_o, norm_posterior=False) #, norm_posterior=False\n",
    "# log_prob_t = log_probability\n",
    "# for i in range(6):\n",
    "#     log_prob_t += logds_norm2unif(samples[:,i], params.IM_PARAMETER_BOUNDS[i][0], params.IM_PARAMETER_BOUNDS[i][1])\n",
    "# for i in range(6,11):\n",
    "#     if i == 6:\n",
    "#         m,s=range2logn(params.IM_PARAMETER_BOUNDS[i][0], params.IM_PARAMETER_BOUNDS[i][1], n_sigma=3)\n",
    "#     else:\n",
    "#         m,s=range2logn(params.IM_PARAMETER_BOUNDS[i][0], params.IM_PARAMETER_BOUNDS[i][1])\n",
    "#     log_prob_t += logds_norm2logn(samples[:,i], m, s)\n",
    "plt.hist(log_probability.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf046f8-011e-4d73-bd1b-1fdb44fc280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths.POSTERIOR_SAVE + \"log_probability.pkl\", \"wb\") as handle:\n",
    "    pickle.dump(log_probability, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = np.argmax(log_probability)\n",
    "# samples_t = torch.clone(samples)\n",
    "# for i in range(6):\n",
    "#     samples_t[:,i] = torch.from_numpy(norm2unif(samples[:,i], params.IM_PARAMETER_BOUNDS[i][0], params.IM_PARAMETER_BOUNDS[i][1]))\n",
    "# for i in range(6,11):\n",
    "#     if i == 6:\n",
    "#         m,s=range2logn(params.IM_PARAMETER_BOUNDS[i][0], params.IM_PARAMETER_BOUNDS[i][1], n_sigma=3)\n",
    "#     else:\n",
    "#         m,s=range2logn(params.IM_PARAMETER_BOUNDS[i][0], params.IM_PARAMETER_BOUNDS[i][1])\n",
    "#     samples_t[:,i] = norm2logn(samples[:,i], m, s)\n",
    "predicted_post = samples[sample_idx]\n",
    "predicted_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_xo = params.IM_SAVE_X0\n",
    "# save_xo = 'x_0_traces.pdf'\n",
    "fig,ax = plot_LFP_traces(t0,x0_trace,savefig=params.IM_SAVE_X0)\n",
    "# save_xo = 'x_0_HTmap.pdf'\n",
    "elec_idx = slice(30,-10)\n",
    "fig,ax = plot_LFP_heatmap(t0,params.IM_Y_DISTANCE[elec_idx],x0_trace[:,elec_idx],vlim='auto',savefig=params.IM_SAVE_X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_lfp = passive_model(params.IM_RANDOM_SAMPLE,whole_trace=True)\n",
    "predicted_lfp = passive_model(predicted_post,whole_trace=True) if params.ACTIVE_CELL is False else active_model(predicted_post, whole_trace=True)\n",
    "\n",
    "fig,ax = plot_LFP_traces(sim.t(),predicted_lfp)\n",
    "start,end = get_spike_window(predicted_lfp,win_size=params.AM_WINDOW_SIZE,align_at=10)\n",
    "predicted_lfp_win = predicted_lfp[start:end,:]\n",
    "\n",
    "savefig = paths.PASSIVE_INFERENCE_SAVE_TRACES if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_SAVE_TRACES\n",
    "fig,ax = plot_LFP_traces(t0,\n",
    "                         predicted_lfp_win,\n",
    "                         savefig=savefig)\n",
    "\n",
    "savefig = paths.PASSIVE_INFERENCE_SAVE_HEATMAPS if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_SAVE_HEATMAPS\n",
    "fig,ax = plot_LFP_heatmap(t0,\n",
    "                          params.IM_Y_DISTANCE[elec_idx],\n",
    "                          predicted_lfp_win[:,elec_idx],\n",
    "                          vlim='auto',\n",
    "                          savefig=savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_corr, max_ind = max_corrcoef(x0_trace,predicted_lfp)\n",
    "print(max_corr,max_ind)\n",
    "max_corr, max_ind = max_corrcoef(x0_trace,predicted_lfp_win)\n",
    "print(max_corr,max_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_file = paths.PASSIVE_INFERENCE_RESULTS_DATA if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_RESULTS_DATA\n",
    "hf = h5py.File(hf_file, 'w')\n",
    "hf.create_dataset('LFP',data=predicted_lfp)\n",
    "hf.create_dataset('samples',data=samples.numpy())\n",
    "hf.create_dataset('log_prob',data=log_probability.numpy())\n",
    "hf.close()\n",
    "\n",
    "mat_file = paths.PASSIVE_INFERENCE_RESULTS_MATLAB_DATA if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_RESULTS_MATLAB_DATA\n",
    "scipy.io.savemat(mat_file,\n",
    "                 {'LFP':predicted_lfp_win[:,elec_idx],'t':t0,'y_dist':params.IM_Y_DISTANCE[elec_idx]})\n",
    "\n",
    "mat_file = paths.PASSIVE_INFERENCE_RESULTS_X0_MATLAB_DATA if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_RESULTS_X0_MATLAB_DATA\n",
    "scipy.io.savemat(mat_file,\n",
    "                 {'LFP':x0_trace[:,elec_idx],'t':t0,'y_dist':params.IM_Y_DISTANCE[elec_idx]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_params = params.IM_GRAPHING_LABELS #= [r'y',r'd',r'$\\theta$',r'h',r'$\\phi$',r'soma radius',r'trunk length',r'trunk radius',r'basal radius',r'tuft radius',r'basal length']\n",
    "fig, axes = analysis.pairplot(samples,\n",
    "                           limits = params.IM_PARAMETER_BOUNDS,\n",
    "                           ticks = params.IM_PARAMETER_BOUNDS,\n",
    "                           figsize=(12,12),\n",
    "                           #points=true_params,\n",
    "                           points_offdiag={'markersize': 6},\n",
    "                           labels = labels_params,\n",
    "                           points_colors='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# labels_params = params.IM_GRAPHING_LABELS\n",
    "bounds_ticks = params.IM_PARAMETER_BOUNDS\n",
    "bounds_ticks[2] = bounds_ticks[4] = [0,3.14]\n",
    "fig, axes = analysis.pairplot(samples,\n",
    "                           limits = params.IM_PARAMETER_BOUNDS,\n",
    "                           ticks = params.IM_PARAMETER_BOUNDS,\n",
    "                           figsize=(25,25),\n",
    "                           #points=true_params,\n",
    "                           points_offdiag={'markersize': 6},\n",
    "                           labels = labels_params,\n",
    "                           points_colors='r')\n",
    "\n",
    "# axes[4][4].set_xlabel('\\u03BB',fontsize = 40)\n",
    "for i in range(len(params.IM_PARAMETER_BOUNDS)):\n",
    "    axes[i][i].tick_params('x',labelsize=15)\n",
    "    axes[i][i].xaxis.label.set_fontsize(40)\n",
    "\n",
    "for i,b in enumerate(params.IM_PARAMETER_BOUNDS):\n",
    "    axes[i][i].set_xticklabels([str(b[0]),str(b[1])],fontsize=30)\n",
    "\n",
    "    \n",
    "save_file = paths.PASSIVE_INFERENCE_SAVE_KDE if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_SAVE_KDE\n",
    "plt.savefig(save_file,bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-crystal",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.Tensor([[350],[50],[np.pi/4], [0.0], [0.8], [400.0], [6.0], [0.5], [0.5], [0.5], [200.0]]).reshape(-1,11)\n",
    "labels_params = params.IM_GRAPHING_LABELS #= [r'y',r'd',r'$\\theta$',r'h',r'$\\phi$',r'soma radius',r'trunk length',r'trunk radius',r'basal radius',r'tuft radius',r'basal length']\n",
    "fig, axes = analysis.pairplot(samples,\n",
    "                           limits = params.IM_PARAMETER_BOUNDS,\n",
    "                           ticks = params.IM_PARAMETER_BOUNDS,\n",
    "                           figsize=(12,12),\n",
    "                           points=points,\n",
    "                           points_offdiag={'markersize': 6},\n",
    "                           labels = labels_params,\n",
    "                           points_colors='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c6d96e-05d9-492b-85ab-11d7c44b217f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
