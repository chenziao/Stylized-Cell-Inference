{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "animated-third",
   "metadata": {},
   "source": [
    "## INFERENCE MODEL\n",
    "Setup inference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fundamental-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.split(sys.path[0])[0])\n",
    "\n",
    "#Dependencies\n",
    "import dill\n",
    "import h5py\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sbi.inference import SNPE, prepare_for_sbi, simulate_for_sbi\n",
    "import sbi.analysis as analysis\n",
    "import sbi.utils as utils\n",
    "from sbi.utils.get_nn_models import posterior_nn  # For SNLE: likelihood_nn(). For SNRE: classifier_nn()\n",
    "from scipy import signal, stats as spstats\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Project Imports\n",
    "import config.params as params\n",
    "import config.paths as paths\n",
    "from stylized_module.base.passive_model_soma_injection import run_pm_simulation\n",
    "from stylized_module.base.active_model_synapse_input import run_am_simulation\n",
    "from stylized_module.models.SummaryStats2D import Stats, cat_output\n",
    "from utils.metrics.corrcoef import corrcoef, max_corrcoef\n",
    "from utils.plotting.plot_results import plot_LFP_traces,plot_LFP_heatmap\n",
    "from utils.spike_window import first_pk_tr, get_spike_window\n",
    "from utils.transform.distribution_transformation import norm2unif, range2logn, norm2logn, logds_norm2unif, logds_norm2logn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-prince",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "canadian-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(123412)\n",
    "\n",
    "def passive_model(param,whole_trace=False):\n",
    "    #Replace theta with random number\n",
    "    theta = [rng.uniform(low=params.IM_THETA_BOUNDS[0], high=params.IM_THETA_BOUNDS[1])]\n",
    "    sim.set_loc_param(torch.cat((torch.zeros(1),param[:2], torch.tensor(theta), param[2:4])))\n",
    "    scalVal = 1 #10 ** param[5]\n",
    "    sim.set_scale(scalVal)\n",
    "    sim.set_geo_param(param[4:])\n",
    "    sim.create_cells()\n",
    "    sim.run()\n",
    "    lfp = sim.get_lfp().T\n",
    "    filtered_lfp = signal.lfilter(filt_b,filt_a,lfp,axis=0) # filter along row of the lfp 2d-array, if each row is a channel\n",
    "    if not whole_trace:\n",
    "        start,end = get_spike_window(filtered_lfp,win_size=params.PM_WINDOW_SIZE,align_at=fst_idx)\n",
    "        filtered_lfp = filtered_lfp[start:end,:]\n",
    "    return filtered_lfp\n",
    "\n",
    "def active_model(param,whole_trace=False):\n",
    "#     biophys = [param[0],-1,-1,param[1],-1,param[2],-1]\n",
    "#     sim.set_biophys(biophys)\n",
    "    \n",
    "    #Replace alpha with random number\n",
    "    alpha = rng.uniform(low=params.IM_ALPHA_BOUNDS[0], high=params.IM_ALPHA_BOUNDS[1])\n",
    "    d = norm2unif(param[1], params.IM_PARAMETER_BOUNDS[1][0], params.IM_PARAMETER_BOUNDS[1][1])\n",
    "    theta = norm2unif(param[2], params.IM_PARAMETER_BOUNDS[2][0], params.IM_PARAMETER_BOUNDS[2][1])\n",
    "    x = d * np.sin(theta)\n",
    "    z = d * np.cos(theta)\n",
    "    \n",
    "    numpy_list = np.array([\n",
    "        x, #x\n",
    "        norm2unif(param[0], params.IM_PARAMETER_BOUNDS[0][0], params.IM_PARAMETER_BOUNDS[0][1]), #y\n",
    "        z, #z\n",
    "        alpha, #alpha\n",
    "        norm2unif(param[3], params.IM_PARAMETER_BOUNDS[3][0], params.IM_PARAMETER_BOUNDS[3][1]), #h\n",
    "        norm2unif(param[4], params.IM_PARAMETER_BOUNDS[4][0], params.IM_PARAMETER_BOUNDS[4][1]) #phi\n",
    "    ])\n",
    "    \n",
    "    sim.set_loc_param(torch.from_numpy(numpy_list))\n",
    "\n",
    "    m1,s1=range2logn(params.IM_PARAMETER_BOUNDS[5][0], params.IM_PARAMETER_BOUNDS[5][1])\n",
    "    m2,s2=range2logn(params.IM_PARAMETER_BOUNDS[6][0], params.IM_PARAMETER_BOUNDS[6][1])\n",
    "    m3,s3=range2logn(params.IM_PARAMETER_BOUNDS[7][0], params.IM_PARAMETER_BOUNDS[7][1])\n",
    "    m4,s4=range2logn(params.IM_PARAMETER_BOUNDS[8][0], params.IM_PARAMETER_BOUNDS[8][1])\n",
    "    m5,s5=range2logn(params.IM_PARAMETER_BOUNDS[9][0], params.IM_PARAMETER_BOUNDS[9][1])\n",
    "    m6,s6=range2logn(params.IM_PARAMETER_BOUNDS[10][0], params.IM_PARAMETER_BOUNDS[10][1])\n",
    "\n",
    "    numpy_list = np.array([\n",
    "        norm2logn(param[5],m1,s1), #r_s\n",
    "        norm2logn(param[6],m2,s2), #l_t\n",
    "        norm2logn(param[7],m3,s3), #r_t\n",
    "        norm2logn(param[8],m4,s4), #r_d\n",
    "        norm2logn(param[9],m5,s5), #r_tu, shouldn't be inferred?\n",
    "        norm2logn(param[10],m6,s6) #l_d\n",
    "    ])\n",
    "\n",
    "    sim.set_geo_param(torch.from_numpy(numpy_list))\n",
    "\n",
    "    scalVal = 1 #10 ** param[5]\n",
    "    sim.set_scale(scalVal)\n",
    "    \n",
    "    sim.set_gmax(params.GT_GMAX)\n",
    "#     scalVal = 10 ** param[4]\n",
    "    sim.set_scale(scalVal)\n",
    "    sim.create_cells()\n",
    "    sim.run()\n",
    "    lfp = sim.get_lfp().T\n",
    "    filtered_lfp = signal.lfilter(filt_b,filt_a,lfp,axis=0) # filter along row of the lfp 2d-array, if each row is a channel\n",
    "    if not whole_trace:\n",
    "        start,end = get_spike_window(filtered_lfp,win_size=params.AM_WINDOW_SIZE,align_at=fst_idx)\n",
    "        filtered_lfp = filtered_lfp[start:end,:]\n",
    "    return filtered_lfp\n",
    "\n",
    "# def Stats(lfp):\n",
    "#     \"\"\"\n",
    "#     Calculates summary statistics\n",
    "#     results = model(params)\n",
    "#     \"\"\"\n",
    "#     lfp = np.asarray(lfp)\n",
    "    \n",
    "#     avg = np.mean(lfp,axis=0) # average voltage of each channel\n",
    "# #     stdDev = np.std(lfp,axis=0) # stDev of the voltage of each channel\n",
    "#     tT = np.argmin(lfp,axis=0)\n",
    "#     tP = np.argmax(lfp,axis=0)\n",
    "#     Troughs = np.take_along_axis(lfp,np.expand_dims(tT,axis=0),axis=0)\n",
    "#     Peaks = np.take_along_axis(lfp,np.expand_dims(tP,axis=0),axis=0)\n",
    "#     relT = tP-tT\n",
    "#     stats_list = [avg,Troughs,Peaks,relT]\n",
    "    \n",
    "#     def statscalc(stats):\n",
    "#         stats = stats.ravel()\n",
    "#         mean = np.mean(stats)\n",
    "#         std = np.std(stats)\n",
    "#         m = np.argmin(stats)\n",
    "#         min_pos = params.IM_Y_DISTANCE[m]\n",
    "#         min_val = stats[m]\n",
    "#         M = np.argmax(stats)\n",
    "#         max_pos = params.IM_Y_DISTANCE[M] \n",
    "#         max_val = stats[M]\n",
    "#         All = np.array([mean,std,min_pos,min_val,max_pos,max_val])\n",
    "#         return All\n",
    "    \n",
    "#     allStats = np.concatenate([statscalc(x) for x in stats_list])\n",
    "#     return allStats\n",
    "\n",
    "# def cat_output(lfp):\n",
    "#     output = np.concatenate((lfp.ravel(),Stats(lfp)))\n",
    "#     return torch.from_numpy(output)\n",
    "\n",
    "def simulation(sim_params):\n",
    "    lfp = passive_model(sim_params) if params.ACTIVE_CELL is False else active_model(sim_params)\n",
    "    return cat_output(lfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "instrumental-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_b,filt_a = signal.butter(params.IM_BUTTERWORTH_ORDER,\n",
    "                              params.IM_CRITICAL_FREQUENCY,\n",
    "                              params.IM_BANDFILTER_TYPE,\n",
    "                              fs=params.IM_FILTER_SAMPLING_RATE)\n",
    "\n",
    "sim, window_size, x0_trace, t0 = run_pm_simulation() if params.ACTIVE_CELL is False else run_am_simulation()\n",
    "\n",
    "fst_idx = first_pk_tr(x0_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "induced-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator, prior = prepare_for_sbi(simulation, params.IM_PRIOR_DISTRIBUTION)\n",
    "x_o = cat_output(x0_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exterior-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the neural density estimator\n",
    "density_estimator_build_fun = posterior_nn(model=params.IM_POSTERIOR_MODEL_ESTIMATOR,\n",
    "                                           embedding_net=params.IM_EMBEDDED_NETWORK,\n",
    "                                           hidden_features=params.IM_POSTERIOR_MODEL_HIDDEN_LAYERS)\n",
    "\n",
    "inference = SNPE(prior=prior,density_estimator=density_estimator_build_fun,show_progress_bars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-billion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5372c63f581c46b280b11de8cd3ad796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 1000 simulations.:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training neural network. Epochs trained:  109\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning bracket width...:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network successfully converged after 110 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning bracket width...: 100%|██████████| 50/50 [00:58<00:00,  1.16s/it]\n",
      "Generating samples: 100%|██████████| 20/20 [01:54<00:00,  5.74s/it]\n",
      "Generating samples: 100%|██████████| 1000/1000 [1:35:06<00:00,  5.71s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9844b051c284b8793d562d4b7473e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 1000 simulations.:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SNPE-C with atomic loss\n"
     ]
    }
   ],
   "source": [
    "posteriors = []\n",
    "proposal = prior\n",
    "\n",
    "for i in range(params.IM_NUMBER_OF_ROUNDS):\n",
    "    theta, x = simulate_for_sbi(simulator,proposal,num_simulations=params.IM_NUMBER_OF_SIMULATIONS)\n",
    "     # In `SNLE` and `SNRE`, you should not pass the `proposal` to `.append_simulations()`\n",
    "#     density_estimator = inference.append_simulations(np.squeeze(theta), np.squeeze(x), proposal=proposal).train()\n",
    "    density_estimator = inference.append_simulations(np.squeeze(theta), x, proposal=proposal).train()\n",
    "    posterior = inference.build_posterior(density_estimator, sample_with=\"mcmc\")\n",
    "    \n",
    "    with open(paths.POSTERIOR_SAVE + str(i) + \"_post.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(posterior, handle)\n",
    "        \n",
    "    with open(paths.POSTERIOR_SAVE + str(i) + \"_de.pkl\", \"wb\") as handle:\n",
    "        pickle.dump(density_estimator, handle)\n",
    "        \n",
    "    posteriors.append(posterior)\n",
    "    proposal = posterior.set_default_x(x_o)\n",
    "    \n",
    "inference._summary_writer = None\n",
    "inference._build_neural_net = None\n",
    "with open(paths.INFERENCER_SAVE + str(i) + \".pkl\", \"wb\") as handle:\n",
    "    pickle.dump(inference, handle)\n",
    "\n",
    "# with open(paths.POSTERIOR_SAVE + \"1_post.pkl\", \"rb\") as handle:\n",
    "#     posterior = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = posterior.sample((1000,), x=x_o, sample_with='mcmc') #, sample_with_mcmc=True\n",
    "\n",
    "#posterior.leakage_correction(x_o, num_rejection_samples=1000)\n",
    "log_probability = posterior.log_prob(samples,x=x_o, norm_posterior=False) #, norm_posterior=False\n",
    "log_prob_t = log_probability\n",
    "for i in range(5):\n",
    "    log_prob_t += logds_norm2unif(samples[:,i], params.IM_PARAMETER_BOUNDS[i][0], params.IM_PARAMETER_BOUNDS[i][1])\n",
    "for i in range(5,11):\n",
    "    m,s=range2logn(params.IM_PARAMETER_BOUNDS[i][0], params.IM_PARAMETER_BOUNDS[i][1])\n",
    "    log_prob_t += logds_norm2logn(samples[:,i], m, s)\n",
    "plt.hist(log_prob_t.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = np.argmax(log_prob_t)\n",
    "samples_t = torch.clone(samples)\n",
    "for i in range(5):\n",
    "    samples_t[:,i] = torch.from_numpy(norm2unif(samples[:,i], params.IM_PARAMETER_BOUNDS[i][0], params.IM_PARAMETER_BOUNDS[i][1]))\n",
    "for i in range(5,11):\n",
    "    m,s=range2logn(params.IM_PARAMETER_BOUNDS[i][0], params.IM_PARAMETER_BOUNDS[i][1])\n",
    "    samples_t[:,i] = norm2logn(samples[:,i], m, s)\n",
    "predicted_post = samples[sample_idx]\n",
    "predicted_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_xo = params.IM_SAVE_X0\n",
    "# save_xo = 'x_0_traces.pdf'\n",
    "fig,ax = plot_LFP_traces(t0,x0_trace,savefig=params.IM_SAVE_X0)\n",
    "# save_xo = 'x_0_HTmap.pdf'\n",
    "elec_idx = slice(30,-10)\n",
    "fig,ax = plot_LFP_heatmap(t0,params.IM_Y_DISTANCE[elec_idx],x0_trace[:,elec_idx],vlim='auto',savefig=params.IM_SAVE_X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_lfp = passive_model(params.IM_RANDOM_SAMPLE,whole_trace=True)\n",
    "predicted_lfp = passive_model(predicted_post,whole_trace=True) if params.ACTIVE_CELL is False else active_model(predicted_post, whole_trace=True)\n",
    "\n",
    "fig,ax = plot_LFP_traces(sim.t(),predicted_lfp)\n",
    "start,end = get_spike_window(predicted_lfp,win_size=params.PM_WINDOW_SIZE,align_at=fst_idx)\n",
    "predicted_lfp_win = predicted_lfp[start:end,:]\n",
    "\n",
    "savefig = paths.PASSIVE_INFERENCE_SAVE_TRACES if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_SAVE_TRACES\n",
    "fig,ax = plot_LFP_traces(t0,\n",
    "                         predicted_lfp_win,\n",
    "                         savefig=savefig)\n",
    "\n",
    "savefig = paths.PASSIVE_INFERENCE_SAVE_HEATMAPS if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_SAVE_HEATMAPS\n",
    "fig,ax = plot_LFP_heatmap(t0,\n",
    "                          params.IM_Y_DISTANCE[elec_idx],\n",
    "                          predicted_lfp_win[:,elec_idx],\n",
    "                          vlim='auto',\n",
    "                          savefig=savefig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_corr, max_ind = max_corrcoef(x0_trace,predicted_lfp)\n",
    "print(max_corr,max_ind)\n",
    "max_corr, max_ind = max_corrcoef(x0_trace,predicted_lfp_win)\n",
    "print(max_corr,max_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_file = paths.PASSIVE_INFERENCE_RESULTS_DATA if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_RESULTS_DATA\n",
    "hf = h5py.File(hf_file, 'w')\n",
    "hf.create_dataset('LFP',data=predicted_lfp)\n",
    "hf.create_dataset('samples',data=samples.numpy())\n",
    "hf.create_dataset('log_prob',data=log_probability.numpy())\n",
    "hf.close()\n",
    "\n",
    "mat_file = paths.PASSIVE_INFERENCE_RESULTS_MATLAB_DATA if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_RESULTS_MATLAB_DATA\n",
    "scipy.io.savemat(mat_file,\n",
    "                 {'LFP':predicted_lfp_win[:,elec_idx],'t':t0,'y_dist':params.IM_Y_DISTANCE[elec_idx]})\n",
    "\n",
    "mat_file = paths.PASSIVE_INFERENCE_RESULTS_X0_MATLAB_DATA if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_RESULTS_X0_MATLAB_DATA\n",
    "scipy.io.savemat(mat_file,\n",
    "                 {'LFP':x0_trace[:,elec_idx],'t':t0,'y_dist':params.IM_Y_DISTANCE[elec_idx]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_params = IM_GRAPHING_LABELS = [r'y',r'd',r'$\\theta$',r'h',r'$\\phi$',r'soma radius',r'trunk length',r'trunk radius',r'basal radius',r'tuft radius',r'basal length']\n",
    "fig, axes = analysis.pairplot(samples_t,\n",
    "                           limits = params.IM_PARAMETER_BOUNDS,\n",
    "                           ticks = params.IM_PARAMETER_BOUNDS,\n",
    "                           figsize=(12,12),\n",
    "                           #points=true_params,\n",
    "                           points_offdiag={'markersize': 6},\n",
    "                           labels = labels_params,\n",
    "                           points_colors='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# labels_params = params.IM_GRAPHING_LABELS\n",
    "bounds_ticks = params.IM_PARAMETER_BOUNDS\n",
    "bounds_ticks[2] = bounds_ticks[4] = [0,3.14]\n",
    "fig, axes = analysis.pairplot(samples_t,\n",
    "                           limits = params.IM_PARAMETER_BOUNDS,\n",
    "                           ticks = params.IM_PARAMETER_BOUNDS,\n",
    "                           figsize=(25,25),\n",
    "                           #points=true_params,\n",
    "                           points_offdiag={'markersize': 6},\n",
    "                           labels = labels_params,\n",
    "                           points_colors='r');\n",
    "\n",
    "# axes[4][4].set_xlabel('\\u03BB',fontsize = 40)\n",
    "for i in range(len(params.IM_PARAMETER_BOUNDS)):\n",
    "    axes[i][i].tick_params('x',labelsize=15)\n",
    "    axes[i][i].xaxis.label.set_fontsize(40)\n",
    "\n",
    "for i,b in enumerate(params.IM_PARAMETER_BOUNDS):\n",
    "    axes[i][i].set_xticklabels([str(b[0]),str(b[1])],fontsize=30)\n",
    "\n",
    "    \n",
    "save_file = paths.PASSIVE_INFERENCE_SAVE_KDE if params.ACTIVE_CELL is False else paths.ACTIVE_INFERENCE_SAVE_KDE\n",
    "plt.savefig(save_file,bbox_inches='tight',transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-crystal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
